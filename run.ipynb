{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "try:\n",
    "    import importlib\n",
    "    importlib.reload(h)\n",
    "    importlib.reload(f)\n",
    "    importlib.reload(d)\n",
    "except NameError: # It hasn't been imported yet\n",
    "    import helpers as h\n",
    "    import implementations as f\n",
    "    import data_processing as d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and feature selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For this to work, the data folder needs to be one level above the project folder and the folder name needs\n",
    "#to be 'data'\n",
    "data_folder = '../data/'\n",
    "x_train, x_test, y_train, train_ids, test_ids = h.load_csv_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\EPFL\\MA1\\ML-project\\run.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/EPFL/MA1/ML-project/run.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train, x_test, y_train, train_ids, test_ids \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mload_csv_data(\u001b[39m\"\u001b[39;49m\u001b[39m../data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\EPFL\\MA1\\ML-project\\helpers.py:30\u001b[0m, in \u001b[0;36mload_csv_data\u001b[1;34m(data_path, sub_sample)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mThis function loads the data and returns the respectinve numpy arrays.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mRemember to put the 3 files in the same folder and to not change the names of the files.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m    test_ids (np.array): ids of test data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\n\u001b[0;32m     24\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m\"\u001b[39m\u001b[39my_train.csv\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     25\u001b[0m     delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     usecols\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(\n\u001b[0;32m     31\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_path, \u001b[39m\"\u001b[39;49m\u001b[39mx_train.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m), delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, skip_header\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\n\u001b[0;32m     34\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_path, \u001b[39m\"\u001b[39m\u001b[39mx_test.csv\u001b[39m\u001b[39m\"\u001b[39m), delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, skip_header\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m train_ids \u001b[39m=\u001b[39m x_train[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mastype(dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2324\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   2320\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2323\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2324\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2325\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2328\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2329\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2324\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2320\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2323\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2324\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2325\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2328\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2329\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:2324\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2320\u001b[0m \u001b[39m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[39m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2322\u001b[0m \u001b[39mif\u001b[39;00m loose:\n\u001b[0;32m   2323\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m-> 2324\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39;49m_loose_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2325\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     rows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2328\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[[conv\u001b[39m.\u001b[39m_strict_call(_r) \u001b[39mfor\u001b[39;00m _r \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2329\u001b[0m               \u001b[39mfor\u001b[39;00m (i, conv) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(converters)]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = h.load_csv_data(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/y_train.npy', y_train)\n",
    "np.save('../data/x_train.npy', x_train)\n",
    "np.save('../data/x_test.npy', x_test)\n",
    "np.save('../data/train_ids.npy', train_ids)\n",
    "np.save('../data/test_ids.npy', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"../data/x_train.npy\")\n",
    "x_test = np.load(\"../data/x_test.npy\")\n",
    "y_train = np.load(\"../data/y_train.npy\")\n",
    "train_ids = np.load(\"../data/train_ids.npy\")\n",
    "test_ids = np.load(\"../data/test_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE',\n",
       "       'SEQNO', '_PSU', 'CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES',\n",
       "       'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1',\n",
       "       'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE',\n",
       "       'HHADULT', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH',\n",
       "       'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BPMEDS',\n",
       "       'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW',\n",
       "       'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2',\n",
       "       'CHCKIDNY', 'DIABETE3', 'DIABAGE2', 'SEX', 'MARITAL', 'EDUCA',\n",
       "       'RENTHOM1', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'VETERAN3',\n",
       "       'EMPLOY1', 'CHILDREN', 'INCOME2', 'INTERNET', 'WEIGHT2', 'HEIGHT3',\n",
       "       'PREGNANT', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK',\n",
       "       'DIFFDRES', 'DIFFALON', 'SMOKE100', 'SMOKDAY2', 'STOPSMK2',\n",
       "       'LASTSMK2', 'USENOW3', 'ALCDAY5', 'AVEDRNK2', 'DRNK3GE5',\n",
       "       'MAXDRNKS', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG',\n",
       "       'VEGETAB1', 'EXERANY2', 'EXRACT11', 'EXEROFT1', 'EXERHMM1',\n",
       "       'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'STRENGTH', 'LMTJOIN3',\n",
       "       'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'SEATBELT', 'FLUSHOT6',\n",
       "       'FLSHTMY2', 'IMFVPLAC', 'PNEUVAC3', 'HIVTST6', 'HIVTSTD3',\n",
       "       'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR',\n",
       "       'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM',\n",
       "       'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1',\n",
       "       'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2',\n",
       "       'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2',\n",
       "       'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2',\n",
       "       'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL',\n",
       "       'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE',\n",
       "       'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM',\n",
       "       'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1',\n",
       "       'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART',\n",
       "       'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU',\n",
       "       'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG',\n",
       "       'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2',\n",
       "       'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3',\n",
       "       'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1',\n",
       "       'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN',\n",
       "       'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD',\n",
       "       'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2',\n",
       "       'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR',\n",
       "       'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK',\n",
       "       'ADMOVE', 'MISTMNT', 'ADANXEV', 'QSTVER', 'QSTLANG', 'MSCODE',\n",
       "       '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_CHISPNC', '_CRACE1',\n",
       "       '_CPRACE', '_CLLCPWT', '_DUALUSE', '_DUALCOR', '_LLCPWT',\n",
       "       '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL',\n",
       "       '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1',\n",
       "       '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1',\n",
       "       '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4',\n",
       "       'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG',\n",
       "       '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_',\n",
       "       '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_',\n",
       "       'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN',\n",
       "       '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM',\n",
       "       '_FRTLT1', '_VEGLT1', '_FRT16', '_VEG23', '_FRUITEX', '_VEGETEX',\n",
       "       '_TOTINDA', 'METVL11_', 'METVL21_', 'MAXVO2_', 'FC60_', 'ACTIN11_',\n",
       "       'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_',\n",
       "       '_MINAC11', '_MINAC21', 'STRFREQ_', 'PAMISS1_', 'PAMIN11_',\n",
       "       'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_',\n",
       "       '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021',\n",
       "       '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1',\n",
       "       '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_FLSHOT6', '_PNEUMO2',\n",
       "       '_AIDTST3'], dtype='<U8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_named all the features names and remove the ID column\n",
    "features_name = np.genfromtxt('../data/x_train.csv', delimiter=',', dtype=str, max_rows=1)[1:] \n",
    "features_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "one paper on internet suggests to use these features : \n",
    "\n",
    " _RFHYPE5, TOLDHI2, _CHOLCHK, _BMI5, SMOKE100, CVDSTRK3, DIABETE3, _TOTINDA, _FRTLT1, _VEGLT1, _RFDRHV5, HLTHPLN1, MEDCOST, GENHLTH, MENTHLTH, PHYSHLTH, DIFFWALK, SEX, _AGEG5YR, EDUCA, and INCOME2\n",
    "\n",
    "We apply a mask to get only these important features.\n",
    "\n",
    "Then using we use our preprocessing function. For feature where the answer is yes or no we make the data binary, ordinal (categorical) variables ares changed to 0,1,2,...,Missing values are replace by the mean of the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the important features\n",
    "features_list = ['_RFHYPE5', 'TOLDHI2', '_CHOLCHK', '_BMI5', 'SMOKE100', 'CVDSTRK3', 'DIABETE3', '_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5', \n",
    "                 'HLTHPLN1', 'MEDCOST', 'GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'DIFFWALK', 'SEX', '_AGEG5YR', 'EDUCA', 'INCOME2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.20628162 0.         ... 1.         1.         0.        ]\n",
      "328135\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "trainMask, testMask = masking((x_train, x_test), features_name, features_list)\n",
    "trainProcessed = d.feature_processing_test(trainMask)\n",
    "\n",
    "#Test data Processing \n",
    "testProcessed  = d.feature_processing_test(testMask)\n",
    "\n",
    "x_train_algo = f.replaceMissingValuesMean(trainProcessed)\n",
    "x_test_algo = f.replaceMissingValuesMean(testProcessed)\n",
    "print(x_train_algo[:,19])\n",
    "print(len(x_train_algo))\n",
    "print(len(features_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "##test chelou\n",
    "#x1_stand=f.standardize(x_train_algo)\n",
    "x_train_stand=np.ones(x_train_algo.shape)\n",
    "x_test_stand=np.ones(x_test_algo.shape)\n",
    "\n",
    "x_trai_stand=f.standardize(x_train_algo)\n",
    "\n",
    "for i in range(len(features_list)):\n",
    "  x_train_stand[i]=f.standardize(x_train_algo[i])\n",
    "  x_test_stand[i]=f.standardize(x_test_algo[i])\n",
    "\n",
    "print(x_trai_stand==x_train_stand)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the preprocessing has been done, we can format the data to be used by the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX_train = np.c_[np.ones((len(x_train_algo), 1)), x_train_algo]\n",
    "tX_test = np.c_[np.ones((len(x_test_algo), 1)), x_test_algo]\n",
    "\n",
    "tX_train = np.c_[np.ones((len(x_train_algo), 1)), x_train_stand]\n",
    "tX_test = np.c_[np.ones((len(x_test_algo), 1)), x_test_stand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_w = [random.choice([1, -1]) for i in range(len(tX_train[0]))]\n",
    "initial_w = np.ones(len(tX_train[0]))\n",
    "max_iter = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation of the dataset in a test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tX_train_train = tX_train[:int(len(tX_train)*0.7)]\n",
    "y_train_train = y_train[:int(len(tX_train)*0.7)]\n",
    "tX_train_test = tX_train[int(len(tX_train)*0.7):]\n",
    "y_train_test = y_train[int(len(tX_train)*0.7):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_progression(w):\n",
    "    # Plot progression of the weights in function of the iteration and progression on the test set\n",
    "    plt.figure(0)\n",
    "    plt.plot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And then, we can run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossMSE(weights, loss, y, x ):\n",
    "    loss_test_set = []\n",
    "\n",
    "    for w in weights:\n",
    "        loss_test_set.append(f.compute_mse(y, x, w))\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.semilogy(loss)\n",
    "    plt.semilogy(loss_test_set)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MSE gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(9/10): Final loss=80.18464962588749\n"
     ]
    }
   ],
   "source": [
    "#Compute gradient descent with MSE as loss function (see functions.py for the function)\n",
    "\n",
    "w_mse_gd, loss_mse_gd = f.mean_squared_error_gd(y_train_train, tX_train_train, initial_w, 10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_test_set = []\n",
    "\n",
    "for w in w_mse_gd:\n",
    "    loss_test_set.append(f.compute_mse(y_train_test, tX_train_test, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.semilogy(loss_mse_gd)\n",
    "plt.semilogy(loss_test_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.08906857914893185\n",
      "F1 score:  0.16356835713419582\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_mse_gd[-1])\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "print(\"F1 score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#h.create_csv_submission(test_ids, y_test_rounded, 'submission_gd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      "\n",
      " [0.04903566 0.04904174 0.04904589 0.04904809 0.04905119 0.04904731\n",
      " 0.04904832 0.04904731 0.04904388 0.04904903 0.04903112 0.04902601\n",
      " 0.04904714 0.04904906 0.04904871 0.04904793 0.04902131 0.04905031\n",
      " 0.04904743 0.04905033 0.04905121 0.04905028] \n",
      "\n",
      " Loss =  1.9711226851960524 \n",
      "\n",
      "*****************************************************************************  \n",
      "\n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  1.0\n"
     ]
    }
   ],
   "source": [
    "#Test the model on the test sample. Do we need to standardize ?\n",
    "\n",
    "y_test = tX_test.dot(w_mse_gd[-1])\n",
    "y_test_rounded = np.where(y_test > 0, 1, -1) #not sure about this line\n",
    "\n",
    "print('weights = \\n\\n', w_mse_gd[-1],'\\n\\n Loss = ', loss_mse_gd[-1],'\\n\\n*****************************************************************************',\n",
    "      ' \\n\\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_rounded == 1)/len(y_test_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run some cross validation to see the best initial weights (as a function of the proportion of 1, -1 and 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MSE SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 999/999: loss=1.4592509266173614, w0=0.719923545336973, w1=0.2878646463939802\n"
     ]
    }
   ],
   "source": [
    "w_mse_sgd, loss_mse_sgd = f.mean_squared_error_sgd(y_train, tX_train, initial_w, 1000, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossMSE(weights, loss, y, x ):\n",
    "    loss_test_set = []\n",
    "\n",
    "    for w in weights:\n",
    "        loss_test_set.append(f.compute_mse(y, x, w))\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.semilogy(loss)\n",
    "    plt.semilogy(loss_test_set)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLossMSE(w_mse_sgd, loss_mse_sgd, y_train_test, tX_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5044646031633161\n",
      "F1 score:  0.06296701819089878\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_mse_sgd[-1])\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [ 0.71992355  0.28786465 -0.00861015 -0.07479877  0.96115535  0.76382322\n",
      "  0.79952306  0.72310688  0.48449989  0.8248332  -0.35291523 -0.51265252\n",
      "  0.74858723  0.80541539  0.77903047  0.78378034 -0.51029633  0.92194084\n",
      "  0.73226863  0.86189295  0.92862269  0.92614267] \n",
      " Loss =  1.4592509266173614 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.4414832828970826\n"
     ]
    }
   ],
   "source": [
    "y_test_sgd = tX_test.dot(w_mse_sgd[-1])\n",
    "y_test_rounded_sgd = np.where(y_test_sgd > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_mse_sgd[-1],'\\n Loss = ', loss_mse_sgd[-1],'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_rounded_sgd == 1)/len(y_test_rounded_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ls, loss_ls = f.least_squares(y_train, tX_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9117237736309058\n",
      "F1 score:  0.036371701042359726\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_ls)\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [-3.66067966e-01  5.75949422e-02  2.27764110e-03 -2.08810289e-04\n",
      " -2.93665345e-02 -6.61348331e-03 -9.02623972e-02 -3.72906967e-01\n",
      " -4.79531853e-02 -9.87913409e-02 -1.52569694e-03 -5.58292682e-03\n",
      " -9.86043000e-02 -4.21581421e-02 -7.34623468e-02  3.67252347e-02\n",
      "  1.72571932e-02 -2.11669545e-01  3.33860048e-02 -6.21783788e-03\n",
      " -4.39318754e-03 -7.36295398e-03] \n",
      " Loss =  0.13733121632804088 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.0026056189945053436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_ls = tX_test.dot(w_ls)\n",
    "y_test_ls = np.where(y_test_ls > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_ls,'\\n Loss = ', loss_ls,'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_ls == 1)/len(y_test_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ridge, loss_ridge = f.ridge_regression(y_train, tX_train, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [-0.16807427  0.03917705  0.00263183 -0.00060332 -0.04608669 -0.03046109\n",
      " -0.09241493 -0.30090331 -0.06105668 -0.09886347 -0.01771055 -0.00968188\n",
      " -0.11182754 -0.0440128  -0.08040227  0.01886485  0.01556599 -0.07420305\n",
      " -0.02540871 -0.01530144 -0.01029129 -0.01434477] \n",
      " Loss =  0.13792607978063323 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.001307380758646541\n"
     ]
    }
   ],
   "source": [
    "y_test_ridge = tX_test.dot(w_ridge)\n",
    "y_test_ridge = np.where(y_test_ridge > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_ridge,'\\n Loss = ', loss_ridge,'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_ridge == 1)/len(y_test_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed_logreg = np.where(y_train == 1, 1, 0)\n",
    "y_train_train_lg = np.where(y_train == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/499): loss=22.228446953619866, w0=0.9088319282565185, w1=0.774423255619819\n",
      "Gradient Descent(1/499): loss=9.611718774381371, w0=0.8176679123012238, w1=0.5488481612199283\n",
      "Gradient Descent(2/499): loss=1.28687327883213, w0=0.7266558084004003, w1=0.323610439031915\n",
      "Gradient Descent(3/499): loss=1.0905442714743465, w0=0.7117236550240043, w1=0.292093444421554\n",
      "Gradient Descent(4/499): loss=1.0209680298350716, w0=0.7050843262580097, w1=0.28412996682435854\n",
      "Gradient Descent(5/499): loss=0.9651266706147152, w0=0.6994541056665075, w1=0.2781157575578648\n",
      "Gradient Descent(6/499): loss=0.9196805520798447, w0=0.6942399818510507, w1=0.27240817064918965\n",
      "Gradient Descent(7/499): loss=0.8819683110273338, w0=0.6892627378443773, w1=0.2665683889722687\n",
      "Gradient Descent(8/499): loss=0.8496157601200154, w0=0.6845022601659031, w1=0.2606701030212248\n",
      "Gradient Descent(9/499): loss=0.8209881234992175, w0=0.6799539292963054, w1=0.2548381813401633\n",
      "Gradient Descent(10/499): loss=0.7950910548661506, w0=0.6755910806580318, w1=0.24910654626740458\n",
      "Gradient Descent(11/499): loss=0.7713430891562554, w0=0.6713768968233914, w1=0.24345089804999467\n",
      "Gradient Descent(12/499): loss=0.7494052907433914, w0=0.667275676458805, w1=0.2378284051560484\n",
      "Gradient Descent(13/499): loss=0.7290747586183076, w0=0.6632570227636764, w1=0.23219599886334866\n",
      "Gradient Descent(14/499): loss=0.7102213222350677, w0=0.6592968271479897, w1=0.22651761649439722\n",
      "Gradient Descent(15/499): loss=0.6927506184594613, w0=0.6553771179985042, w1=0.22076683953867748\n",
      "Gradient Descent(16/499): loss=0.6765831069969753, w0=0.6514854861294337, w1=0.21492740409236155\n",
      "Gradient Descent(17/499): loss=0.6616429078039279, w0=0.6476143318625053, w1=0.20899258882545646\n",
      "Gradient Descent(18/499): loss=0.6478527692700583, w0=0.6437600285067161, w1=0.2029639511183989\n",
      "Gradient Descent(19/499): loss=0.6351327712296176, w0=0.6399220563446495, w1=0.19684969352311024\n",
      "Gradient Descent(20/499): loss=0.623401109135539, w0=0.6361021561238983, w1=0.19066288103780282\n",
      "Gradient Descent(21/499): loss=0.6125758110555022, w0=0.6323035502087309, w1=0.1844196974445413\n",
      "Gradient Descent(22/499): loss=0.6025766374861247, w0=0.6285302716389773, w1=0.1781378882004095\n",
      "Gradient Descent(23/499): loss=0.5933267354352844, w0=0.6247866260729835, w1=0.1718354836639065\n",
      "Gradient Descent(24/499): loss=0.584753858909778, w0=0.621076793575684, w1=0.1655298402579641\n",
      "Gradient Descent(25/499): loss=0.5767911261737454, w0=0.617404561431678, w1=0.1592369903321275\n",
      "Gradient Descent(26/499): loss=0.5693773707776038, w0=0.6137731685654546, w1=0.15297126042816037\n",
      "Gradient Descent(27/499): loss=0.5624571777588648, w0=0.6101852372940005, w1=0.1467451027331751\n",
      "Gradient Descent(28/499): loss=0.5559806989180265, w0=0.606642767963793, w1=0.14056908226759696\n",
      "Gradient Descent(29/499): loss=0.5499033279018578, w0=0.603147174855594, w1=0.13445196813115975\n",
      "Gradient Descent(30/499): loss=0.5441852975661645, w0=0.5996993459864705, w1=0.12840088673855812\n",
      "Gradient Descent(31/499): loss=0.5387912444418679, w0=0.5962997139293137, w1=0.1224215054303093\n",
      "Gradient Descent(32/499): loss=0.5336897704747617, w0=0.5929483288088864, w1=0.11651822438466317\n",
      "Gradient Descent(33/499): loss=0.5288530210616451, w0=0.5896449279073259, w1=0.11069436258260851\n",
      "Gradient Descent(34/499): loss=0.5242562904101007, w0=0.5863889987639495, w1=0.10495232951528843\n",
      "Gradient Descent(35/499): loss=0.5198776597678892, w0=0.5831798343677659, w1=0.09929377853986376\n",
      "Gradient Descent(36/499): loss=0.5156976704589129, w0=0.5800165801582919, w1=0.09371974060006183\n",
      "Gradient Descent(37/499): loss=0.5116990313874206, w0=0.5768982732212132, w1=0.08823073877157755\n",
      "Gradient Descent(38/499): loss=0.5078663593171249, w0=0.5738238744229252, w1=0.08282688507557441\n",
      "Gradient Descent(39/499): loss=0.5041859494952527, w0=0.5707922943780107, w1=0.07750796147270703\n",
      "Gradient Descent(40/499): loss=0.5006455738598053, w0=0.5678024141649946, w1=0.07227348709128667\n",
      "Gradient Descent(41/499): loss=0.4972343039936514, w0=0.564853101653446, w1=0.06712277368886199\n",
      "Gradient Descent(42/499): loss=0.49394235607110115, w0=0.5619432242164272, w1=0.06205497118643444\n",
      "Gradient Descent(43/499): loss=0.4907609552140502, w0=0.5590716584995662, w1=0.057069104906882134\n",
      "Gradient Descent(44/499): loss=0.4876822168915404, w0=0.5562372978153979, w1=0.05216410592956735\n",
      "Gradient Descent(45/499): loss=0.48469904323030183, w0=0.5534390576364647, w1=0.047338835761944455\n",
      "Gradient Descent(46/499): loss=0.4818050323369739, w0=0.5506758795764324, w1=0.04259210633674574\n",
      "Gradient Descent(47/499): loss=0.47899439895484, w0=0.5479467341761336, w1=0.037922696174300344\n",
      "Gradient Descent(48/499): loss=0.4762619049834334, w0=0.5452506227506501, w1=0.03332936340439237\n",
      "Gradient Descent(49/499): loss=0.47360279857571697, w0=0.5425865785032122, w1=0.028810856219445416\n",
      "Gradient Descent(50/499): loss=0.4710127606940892, w0=0.5399536670705061, w1=0.024365921228432508\n",
      "Gradient Descent(51/499): loss=0.46848785815379435, w0=0.5373509866305445, w1=0.019993310096114582\n",
      "Gradient Descent(52/499): loss=0.4660245023116055, w0=0.5347776676772916, w1=0.01569178478238693\n",
      "Gradient Descent(53/499): loss=0.4636194126705026, w0=0.5322328725445711, w1=0.011460121639242142\n",
      "Gradient Descent(54/499): loss=0.46126958476912944, w0=0.5297157947444595, w1=0.007297114576000042\n",
      "Gradient Descent(55/499): loss=0.45897226180976863, w0=0.5272256581715249, w1=0.003201577465172436\n",
      "Gradient Descent(56/499): loss=0.4567249095520164, w0=0.5247617162132419, w1=-0.0008276540699250542\n",
      "Gradient Descent(57/499): loss=0.4545251940627269, w0=0.5223232507981378, w1=-0.00479172137022095\n",
      "Gradient Descent(58/499): loss=0.45237096196745513, w0=0.5199095714062406, w1=-0.008691741863843966\n",
      "Gradient Descent(59/499): loss=0.45026022289572665, w0=0.5175200140608588, w1=-0.012528808519270816\n",
      "Gradient Descent(60/499): loss=0.44819113385306775, w0=0.5151539403163188, w1=-0.01630398956488536\n",
      "Gradient Descent(61/499): loss=0.4461619852877023, w0=0.5128107362528002, w1=-0.02001832842258254\n",
      "Gradient Descent(62/499): loss=0.4441711886499919, w0=0.5104898114866424, w1=-0.023672843812408324\n",
      "Gradient Descent(63/499): loss=0.44221726526871685, w0=0.5081905982023165, w1=-0.02726852999290911\n",
      "Gradient Descent(64/499): loss=0.4402988363907548, w0=0.5059125502105302, w1=-0.03080635710817744\n",
      "Gradient Descent(65/499): loss=0.4384146142501353, w0=0.5036551420355808, w1=-0.034287271617775075\n",
      "Gradient Descent(66/499): loss=0.436563394049233, w0=0.5014178680340078, w1=-0.03771219678999299\n",
      "Gradient Descent(67/499): loss=0.4347440467494069, w0=0.4992002415457682, w1=-0.04108203324243448\n",
      "Gradient Descent(68/499): loss=0.4329555125810003, w0=0.4970017940785166, w1=-0.04439765951681802\n",
      "Gradient Descent(69/499): loss=0.4311967951935532, w0=0.49482207452507626, w1=-0.0476599326772989\n",
      "Gradient Descent(70/499): loss=0.4294669563765971, w0=0.492660648413812, w1=-0.05086968892359414\n",
      "Gradient Descent(71/499): loss=0.42776511128967454, w0=0.49051709719133324, w1=-0.05402774421183526\n",
      "Gradient Descent(72/499): loss=0.4260904241474434, w0=0.48839101753674696, w1=-0.05713489487743024\n",
      "Gradient Descent(73/499): loss=0.424442104312018, w0=0.48628202070653215, w1=-0.06019191825533669\n",
      "Gradient Descent(74/499): loss=0.42281940275020513, w0=0.48418973190900305, w1=-0.06319957329407545\n",
      "Gradient Descent(75/499): loss=0.4212216088181064, w0=0.4821137897072632, w1=-0.06615860116057896\n",
      "Gradient Descent(76/499): loss=0.419648047339779, w0=0.48005384544951407, w1=-0.06906972583360156\n",
      "Gradient Descent(77/499): loss=0.4180980759503519, w0=0.4780095627255663, w1=-0.07193365468393989\n",
      "Gradient Descent(78/499): loss=0.4165710826772496, w0=0.47598061684840226, w1=-0.07475107904014155\n",
      "Gradient Descent(79/499): loss=0.4150664837360422, w0=0.473966694359654, w1=-0.07752267473873331\n",
      "Gradient Descent(80/499): loss=0.41358372151996425, w0=0.47196749255788273, w1=-0.08024910265829024\n",
      "Gradient Descent(81/499): loss=0.4121222627643811, w0=0.46998271904857813, w1=-0.0829310092369047\n",
      "Gradient Descent(82/499): loss=0.41068159686944244, w0=0.46801209131483107, w1=-0.08556902697280766\n",
      "Gradient Descent(83/499): loss=0.40926123436591544, w0=0.46605533630767215, w1=-0.0881637749080523\n",
      "Gradient Descent(84/499): loss=0.40786070551073567, w0=0.4641121900551105, w1=-0.09071585909529709\n",
      "Gradient Descent(85/499): loss=0.4064795590001822, w0=0.46218239728894867, w1=-0.09322587304782796\n",
      "Gradient Descent(86/499): loss=0.40511736078980665, w0=0.46026571108849323, w1=-0.09569439817304048\n",
      "Gradient Descent(87/499): loss=0.40377369301133287, w0=0.45836189254032195, w1=-0.09812200418966761\n",
      "Gradient Descent(88/499): loss=0.40244815297771025, w0=0.45647071041331116, w1=-0.10050924952908832\n",
      "Gradient Descent(89/499): loss=0.40114035226836314, w0=0.4545919408481666, w1=-0.10285668172109141\n",
      "Gradient Descent(90/499): loss=0.39984991588746266, w0=0.4527253670607412, w1=-0.1051648377644967\n",
      "Gradient Descent(91/499): loss=0.398576481488721, w0=0.4508707790584602, w1=-0.10743424448305748\n",
      "Gradient Descent(92/499): loss=0.3973196986608406, w0=0.4490279733692115, w1=-0.10966541886708121\n",
      "Gradient Descent(93/499): loss=0.3960792282682984, w0=0.4471967527820927, w1=-0.11185886840121531\n",
      "Gradient Descent(94/499): loss=0.394854741842643, w0=0.4453769260994391, w1=-0.11401509137884838\n",
      "Gradient Descent(95/499): loss=0.39364592101993506, w0=0.44356830789958984, w1=-0.11613457720357885\n",
      "Gradient Descent(96/499): loss=0.3924524570203566, w0=0.4417707183098775, w1=-0.11821780667820045\n",
      "Gradient Descent(97/499): loss=0.39127405016638767, w0=0.4399839827893546, w1=-0.12026525228165\n",
      "Gradient Descent(98/499): loss=0.39011040943626407, w0=0.4382079319207973, w1=-0.12227737843435665\n",
      "Gradient Descent(99/499): loss=0.38896125204973925, w0=0.4364424012115529, w1=-0.12425464175242433\n",
      "Gradient Descent(100/499): loss=0.3878263030834276, w0=0.43468723090281747, w1=-0.12619749129107016\n",
      "Gradient Descent(101/499): loss=0.38670529511325674, w0=0.4329422657869567, w1=-0.12810636877773238\n",
      "Gradient Descent(102/499): loss=0.3855979678817738, w0=0.4312073550325008, w1=-0.1299817088352509\n",
      "Gradient Descent(103/499): loss=0.3845040679882449, w0=0.4294823520164641, w1=-0.13182393919551308\n",
      "Gradient Descent(104/499): loss=0.3834233485996717, w0=0.4277671141636605, w1=-0.1336334809039462\n",
      "Gradient Descent(105/499): loss=0.38235556918101316, w0=0.42606150279269983, w1=-0.13541074851522703\n",
      "Gradient Descent(106/499): loss=0.3813004952430427, w0=0.4243653829683704, w1=-0.1371561502805678\n",
      "Gradient Descent(107/499): loss=0.3802578981064116, w0=0.4226786233601243, w1=-0.13887008832692627\n",
      "Gradient Descent(108/499): loss=0.37922755468061453, w0=0.4210010961063991, w1=-0.14055295882847668\n",
      "Gradient Descent(109/499): loss=0.37820924725665617, w0=0.41933267668452195, w1=-0.14220515217066698\n",
      "Gradient Descent(110/499): loss=0.3772027633123305, w0=0.41767324378595516, w1=-0.14382705310717714\n",
      "Gradient Descent(111/499): loss=0.37620789532910787, w0=0.4160226791966535, w1=-0.1454190409100818\n",
      "Gradient Descent(112/499): loss=0.37522444061971955, w0=0.41438086768231513, w1=-0.14698148951351114\n",
      "Gradient Descent(113/499): loss=0.3742522011655974, w0=0.4127476968783194, w1=-0.14851476765109176\n",
      "Gradient Descent(114/499): loss=0.37329098346340217, w0=0.41112305718415254, w1=-0.1500192389874409\n",
      "Gradient Descent(115/499): loss=0.3723405983799428, w0=0.40950684166213364, w1=-0.15149526224397614\n",
      "Gradient Descent(116/499): loss=0.3714008610148366, w0=0.4078989459402615, w1=-0.1529431913192936\n",
      "Gradient Descent(117/499): loss=0.3704715905703259, w0=0.4062992681190102, w1=-0.15436337540435824\n",
      "Gradient Descent(118/499): loss=0.3695526102277109, w0=0.40470770868191036, w1=-0.15575615909274032\n",
      "Gradient Descent(119/499): loss=0.3686437470299017, w0=0.40312417040976023, w1=-0.15712188248612352\n",
      "Gradient Descent(120/499): loss=0.3677448317696413, w0=0.4015485582983165, w1=-0.1584608812953013\n",
      "Gradient Descent(121/499): loss=0.36685569888297886, w0=0.3999807794793231, w1=-0.15977348693686982\n",
      "Gradient Descent(122/499): loss=0.36597618634761836, w0=0.39842074314474113, w1=-0.16106002662581723\n",
      "Gradient Descent(123/499): loss=0.3651061355857901, w0=0.39686836047404944, w1=-0.16232082346420176\n",
      "Gradient Descent(124/499): loss=0.36424539137132794, w0=0.39532354456449115, w1=-0.1635561965261028\n",
      "Gradient Descent(125/499): loss=0.36339380174065844, w0=0.39378621036414607, w1=-0.16476646093902175\n",
      "Gradient Descent(126/499): loss=0.3625512179074346, w0=0.39225627460771506, w1=-0.16595192796190297\n",
      "Gradient Descent(127/499): loss=0.36171749418056737, w0=0.3907336557549059, w1=-0.1671129050599368\n",
      "Gradient Descent(128/499): loss=0.36089248788542827, w0=0.3892182739313157, w1=-0.16824969597630102\n",
      "Gradient Descent(129/499): loss=0.3600760592880195, w0=0.38771005087170907, w1=-0.16936260080099025\n",
      "Gradient Descent(130/499): loss=0.3592680715219192, w0=0.3862089098655948, w1=-0.170451916036876\n",
      "Gradient Descent(131/499): loss=0.35846839051782886, w0=0.3847147757050083, w1=-0.17151793466313472\n",
      "Gradient Descent(132/499): loss=0.35767688493556343, w0=0.3832275746344109, w1=-0.1725609461961745\n",
      "Gradient Descent(133/499): loss=0.3568934260983363, w0=0.38174723430262003, w1=-0.1735812367481861\n",
      "Gradient Descent(134/499): loss=0.35611788792920834, w0=0.38027368371668835, w1=-0.17457908908343775\n",
      "Gradient Descent(135/499): loss=0.355350146889572, w0=0.37880685319765267, w1=-0.17555478267242872\n",
      "Gradient Descent(136/499): loss=0.35459008191956337, w0=0.3773466743380771, w1=-0.1765085937440103\n",
      "Gradient Descent(137/499): loss=0.35383757438029234, w0=0.37589307996131743, w1=-0.17744079533557916\n",
      "Gradient Descent(138/499): loss=0.35309250799779973, w0=0.37444600408243683, w1=-0.17835165734144273\n",
      "Gradient Descent(139/499): loss=0.3523547688086489, w0=0.3730053818707057, w1=-0.17924144655945096\n",
      "Gradient Descent(140/499): loss=0.3516242451070755, w0=0.3715711496136208, w1=-0.18011042673598598\n",
      "Gradient Descent(141/499): loss=0.35090082739361617, w0=0.3701432446823821, w1=-0.18095885860939523\n",
      "Gradient Descent(142/499): loss=0.3501844083251498, w0=0.3687216054987669, w1=-0.18178699995195075\n",
      "Gradient Descent(143/499): loss=0.349474882666288, w0=0.36730617150334505, w1=-0.18259510561041264\n",
      "Gradient Descent(144/499): loss=0.3487721472420547, w0=0.3658968831249785, w1=-0.1833834275452715\n",
      "Gradient Descent(145/499): loss=0.3480761008918004, w0=0.36449368175155394, w1=-0.18415221486874037\n",
      "Gradient Descent(146/499): loss=0.34738664442430317, w0=0.3630965097018966, w1=-0.18490171388156368\n",
      "Gradient Descent(147/499): loss=0.34670368057400675, w0=0.36170531019881635, w1=-0.1856321681087073\n",
      "Gradient Descent(148/499): loss=0.3460271139583549, w0=0.3603200273432394, w1=-0.18634381833399033\n",
      "Gradient Descent(149/499): loss=0.34535685103618086, w0=0.35894060608938033, w1=-0.18703690263371628\n",
      "Gradient Descent(150/499): loss=0.3446928000671126, w0=0.35756699222091076, w1=-0.18771165640935855\n",
      "Gradient Descent(151/499): loss=0.3440348710719643, w0=0.3561991323280835, w1=-0.18836831241935206\n",
      "Gradient Descent(152/499): loss=0.3433829757940742, w0=0.3548369737857713, w1=-0.18900710081003982\n",
      "Gradient Descent(153/499): loss=0.34273702766156444, w0=0.3534804647323826, w1=-0.1896282491458217\n",
      "Gradient Descent(154/499): loss=0.34209694175049066, w0=0.35212955404961666, w1=-0.19023198243854877\n",
      "Gradient Descent(155/499): loss=0.3414626347488562, w0=0.35078419134302263, w1=-0.19081852317620557\n",
      "Gradient Descent(156/499): loss=0.3408340249214645, w0=0.3494443269233287, w1=-0.19138809135091908\n",
      "Gradient Descent(157/499): loss=0.34021103207558584, w0=0.34810991178850853, w1=-0.1919409044863322\n",
      "Gradient Descent(158/499): loss=0.33959357752741726, w0=0.34678089760655306, w1=-0.19247717766437664\n",
      "Gradient Descent(159/499): loss=0.33898158406931217, w0=0.3454572366989184, w1=-0.19299712355147838\n",
      "Gradient Descent(160/499): loss=0.33837497593776006, w0=0.3441388820246198, w1=-0.19350095242422743\n",
      "Gradient Descent(161/499): loss=0.337773678782098, w0=0.3428257871649446, w1=-0.19398887219454064\n",
      "Gradient Descent(162/499): loss=0.33717761963393345, w0=0.3415179063087574, w1=-0.19446108843434629\n",
      "Gradient Descent(163/499): loss=0.3365867268772631, w0=0.34021519423837154, w1=-0.19491780439981587\n",
      "Gradient Descent(164/499): loss=0.3360009302192675, w0=0.33891760631596257, w1=-0.19535922105516823\n",
      "Gradient Descent(165/499): loss=0.3354201606617693, w0=0.33762509847050026, w1=-0.19578553709606875\n",
      "Gradient Descent(166/499): loss=0.33484435047333533, w0=0.33633762718517635, w1=-0.1961969489726457\n",
      "Gradient Descent(167/499): loss=0.33427343316201175, w0=0.33505514948530646, w1=-0.19659365091214404\n",
      "Gradient Descent(168/499): loss=0.3337073434486732, w0=0.3337776229266855, w1=-0.1969758349412357\n",
      "Gradient Descent(169/499): loss=0.3331460172409757, w0=0.3325050055843769, w1=-0.19734369090800447\n",
      "Gradient Descent(170/499): loss=0.3325893916078978, w0=0.3312372560419159, w1=-0.1976974065036221\n",
      "Gradient Descent(171/499): loss=0.3320374047548565, w0=0.3299743333809096, w1=-0.19803716728373166\n",
      "Gradient Descent(172/499): loss=0.3314899959993872, w0=0.3287161971710155, w1=-0.19836315668955246\n",
      "Gradient Descent(173/499): loss=0.33094710574737213, w0=0.3274628074602826, w1=-0.1986755560687204\n",
      "Gradient Descent(174/499): loss=0.3304086754698084, w0=0.32621412476583783, w1=-0.19897454469587697\n",
      "Gradient Descent(175/499): loss=0.32987464768010116, w0=0.32497011006490395, w1=-0.19926029979301813\n",
      "Gradient Descent(176/499): loss=0.3293449659118719, w0=0.32373072478613324, w1=-0.1995329965496147\n",
      "Gradient Descent(177/499): loss=0.3288195746972705, w0=0.3224959308012431, w1=-0.19979280814251463\n",
      "Gradient Descent(178/499): loss=0.3282984195457793, w0=0.3212656904169404, w1=-0.20003990575563635\n",
      "Gradient Descent(179/499): loss=0.32778144692349925, w0=0.3200399663671217, w1=-0.20027445859946272\n",
      "Gradient Descent(180/499): loss=0.3272686042329069, w0=0.3188187218053365, w1=-0.20049663393034334\n",
      "Gradient Descent(181/499): loss=0.3267598397930729, w0=0.31760192029750284, w1=-0.20070659706961338\n",
      "Gradient Descent(182/499): loss=0.3262551028203308, w0=0.3163895258148629, w1=-0.20090451142253551\n",
      "Gradient Descent(183/499): loss=0.32575434340938747, w0=0.31518150272716855, w1=-0.20109053849707206\n",
      "Gradient Descent(184/499): loss=0.32525751251486423, w0=0.3139778157960864, w1=-0.20126483792249286\n",
      "Gradient Descent(185/499): loss=0.3247645619332599, w0=0.3127784301688128, w1=-0.20142756746782506\n",
      "Gradient Descent(186/499): loss=0.324275444285327, w0=0.3115833113718886, w1=-0.20157888306014934\n",
      "Gradient Descent(187/499): loss=0.3237901129988508, w0=0.31039242530520617, w1=-0.20171893880274774\n",
      "Gradient Descent(188/499): loss=0.32330852229182266, w0=0.3092057382361987, w1=-0.20184788699310713\n",
      "Gradient Descent(189/499): loss=0.32283062715599986, w0=0.30802321679420447, w1=-0.20196587814078246\n",
      "Gradient Descent(190/499): loss=0.32235638334084254, w0=0.30684482796499835, w1=-0.20207306098512334\n",
      "Gradient Descent(191/499): loss=0.32188574733781716, w0=0.3056705390854825, w1=-0.2021695825128673\n",
      "Gradient Descent(192/499): loss=0.32141867636506377, w0=0.3045003178385297, w1=-0.20225558797560236\n",
      "Gradient Descent(193/499): loss=0.3209551283524128, w0=0.30333413224797284, w1=-0.20233122090710243\n",
      "Gradient Descent(194/499): loss=0.3204950619267469, w0=0.3021719506737331, w1=-0.20239662314053702\n",
      "Gradient Descent(195/499): loss=0.32003843639770035, w0=0.30101374180708185, w1=-0.20245193482555823\n",
      "Gradient Descent(196/499): loss=0.31958521174368437, w0=0.2998594746660297, w1=-0.2024972944452667\n",
      "Gradient Descent(197/499): loss=0.31913534859823767, w0=0.29870911859083726, w1=-0.20253283883305823\n",
      "Gradient Descent(198/499): loss=0.31868880823668705, w0=0.29756264323964254, w1=-0.20255870318935298\n",
      "Gradient Descent(199/499): loss=0.3182455525631166, w0=0.29642001858419975, w1=-0.20257502109820824\n",
      "Gradient Descent(200/499): loss=0.31780554409763667, w0=0.29528121490572445, w1=-0.20258192454381657\n",
      "Gradient Descent(201/499): loss=0.3173687459639439, w0=0.294146202790841, w1=-0.20257954392688973\n",
      "Gradient Descent(202/499): loss=0.31693512187716855, w0=0.29301495312762743, w1=-0.20256800808093023\n",
      "Gradient Descent(203/499): loss=0.3165046361319994, w0=0.29188743710175385, w1=-0.20254744428839036\n",
      "Gradient Descent(204/499): loss=0.31607725359108285, w0=0.2907636261927104, w1=-0.20251797829672033\n",
      "Gradient Descent(205/499): loss=0.31565293967368674, w0=0.2896434921701208, w1=-0.2024797343343056\n",
      "Gradient Descent(206/499): loss=0.31523166034462424, w0=0.28852700709013807, w1=-0.20243283512629415\n",
      "Gradient Descent(207/499): loss=0.3148133821034322, w0=0.28741414329191894, w1=-0.20237740191031395\n",
      "Gradient Descent(208/499): loss=0.3143980719737962, w0=0.28630487339417404, w1=-0.20231355445208124\n",
      "Gradient Descent(209/499): loss=0.31398569749321775, w0=0.28519917029178976, w1=-0.20224141106089982\n",
      "Gradient Descent(210/499): loss=0.31357622670291785, w0=0.2840970071525203, w1=-0.20216108860505141\n",
      "Gradient Descent(211/499): loss=0.31316962813797017, w0=0.2829983574137458, w1=-0.20207270252707757\n",
      "Gradient Descent(212/499): loss=0.31276587081765905, w0=0.28190319477929476, w1=-0.20197636685895295\n",
      "Gradient Descent(213/499): loss=0.3123649242360583, w0=0.28081149321632776, w1=-0.20187219423715036\n",
      "Gradient Descent(214/499): loss=0.3119667583528217, w0=0.2797232269522801, w1=-0.20176029591759737\n",
      "Gradient Descent(215/499): loss=0.3115713435841854, w0=0.2786383704718614, w1=-0.20164078179052455\n",
      "Gradient Descent(216/499): loss=0.31117865079417095, w0=0.27755689851410986, w1=-0.2015137603952055\n",
      "Gradient Descent(217/499): loss=0.3107886512859902, w0=0.27647878606949855, w1=-0.20137933893458826\n",
      "Gradient Descent(218/499): loss=0.3104013167936429, w0=0.2754040083770927, w1=-0.20123762328981856\n",
      "Gradient Descent(219/499): loss=0.3100166194737035, w0=0.27433254092175563, w1=-0.20108871803465433\n",
      "Gradient Descent(220/499): loss=0.3096345318972936, w0=0.2732643594314012, w1=-0.2009327264497717\n",
      "Gradient Descent(221/499): loss=0.30925502704223434, w0=0.272199439874292, w1=-0.20076975053696236\n",
      "Gradient Descent(222/499): loss=0.3088780782853744, w0=0.2711377584563809, w1=-0.20059989103322198\n",
      "Gradient Descent(223/499): loss=0.3085036593950898, w0=0.2700792916186946, w1=-0.20042324742472994\n",
      "Gradient Descent(224/499): loss=0.30813174452395165, w0=0.26902401603475806, w1=-0.20023991796071985\n",
      "Gradient Descent(225/499): loss=0.307762308201556, w0=0.26797190860805814, w1=-0.20004999966724119\n",
      "Gradient Descent(226/499): loss=0.30739532532751457, w0=0.2669229464695452, w1=-0.1998535883608116\n",
      "Gradient Descent(227/499): loss=0.3070307711645994, w0=0.2658771069751714, w1=-0.19965077866196\n",
      "Gradient Descent(228/499): loss=0.3066686213320399, w0=0.2648343677034649, w1=-0.1994416640086603\n",
      "Gradient Descent(229/499): loss=0.30630885179896783, w0=0.2637947064531379, w1=-0.19922633666965578\n",
      "Gradient Descent(230/499): loss=0.3059514388780059, w0=0.2627581012407287, w1=-0.19900488775767383\n",
      "Gradient Descent(231/499): loss=0.30559635921899797, w0=0.26172453029827575, w1=-0.19877740724253132\n",
      "Gradient Descent(232/499): loss=0.30524358980287536, w0=0.26069397207102346, w1=-0.1985439839641303\n",
      "Gradient Descent(233/499): loss=0.3048931079356591, w0=0.2596664052151581, w1=-0.19830470564534422\n",
      "Gradient Descent(234/499): loss=0.30454489124258943, w0=0.2586418085955738, w1=-0.19805965890479446\n",
      "Gradient Descent(235/499): loss=0.3041989176623865, w0=0.25762016128366705, w1=-0.19780892926951738\n",
      "Gradient Descent(236/499): loss=0.30385516544163216, w0=0.2566014425551595, w1=-0.19755260118752171\n",
      "Gradient Descent(237/499): loss=0.30351361312927494, w0=0.2555856318879479, w1=-0.19729075804023669\n",
      "Gradient Descent(238/499): loss=0.3031742395712532, w0=0.2545727089599809, w1=-0.19702348215485035\n",
      "Gradient Descent(239/499): loss=0.3028370239052318, w0=0.25356265364716124, w1=-0.19675085481653903\n",
      "Gradient Descent(240/499): loss=0.3025019455554538, w0=0.252555446021274, w1=-0.19647295628058703\n",
      "Gradient Descent(241/499): loss=0.30216898422769994, w0=0.25155106634793883, w1=-0.19618986578439768\n",
      "Gradient Descent(242/499): loss=0.30183811990435677, w0=0.25054949508458685, w1=-0.19590166155939504\n",
      "Gradient Descent(243/499): loss=0.30150933283958814, w0=0.24955071287846067, w1=-0.19560842084281696\n",
      "Gradient Descent(244/499): loss=0.30118260355460896, w0=0.24855470056463785, w1=-0.19531021988939948\n",
      "Gradient Descent(245/499): loss=0.3008579128330588, w0=0.24756143916407658, w1=-0.1950071339829527\n",
      "Gradient Descent(246/499): loss=0.30053524171647195, w0=0.24657090988168354, w1=-0.1946992374478285\n",
      "Gradient Descent(247/499): loss=0.30021457149984315, w0=0.24558309410440343, w1=-0.19438660366028024\n",
      "Gradient Descent(248/499): loss=0.2998958837272838, w0=0.24459797339932965, w1=-0.19406930505971465\n",
      "Gradient Descent(249/499): loss=0.2995791601877708, w0=0.24361552951183565, w1=-0.1937474131598364\n",
      "Gradient Descent(250/499): loss=0.29926438291098134, w0=0.2426357443637268, w1=-0.19342099855968523\n",
      "Gradient Descent(251/499): loss=0.29895153416321457, w0=0.24165860005141218, w1=-0.19309013095456654\n",
      "Gradient Descent(252/499): loss=0.2986405964433973, w0=0.24068407884409598, w1=-0.19275487914687509\n",
      "Gradient Descent(253/499): loss=0.29833155247916987, w0=0.23971216318198832, w1=-0.19241531105681292\n",
      "Gradient Descent(254/499): loss=0.298024385223054, w0=0.23874283567453486, w1=-0.1920714937330009\n",
      "Gradient Descent(255/499): loss=0.29771907784869756, w0=0.23777607909866527, w1=-0.19172349336298536\n",
      "Gradient Descent(256/499): loss=0.29741561374719416, w0=0.2368118763970599, w1=-0.19137137528363926\n",
      "Gradient Descent(257/499): loss=0.29711397652347915, w0=0.2358502106764345, w1=-0.191015203991459\n",
      "Gradient Descent(258/499): loss=0.2968141499927972, w0=0.23489106520584294, w1=-0.1906550431527567\n",
      "Gradient Descent(259/499): loss=0.2965161181772395, w0=0.23393442341499718, w1=-0.19029095561374912\n",
      "Gradient Descent(260/499): loss=0.29621986530235256, w0=0.23298026889260465, w1=-0.1899230034105429\n",
      "Gradient Descent(261/499): loss=0.295925375793811, w0=0.23202858538472274, w1=-0.1895512477790171\n",
      "Gradient Descent(262/499): loss=0.2956326342741597, w0=0.23107935679312985, w1=-0.18917574916460347\n",
      "Gradient Descent(263/499): loss=0.29534162555961824, w0=0.23013256717371325, w1=-0.18879656723196464\n",
      "Gradient Descent(264/499): loss=0.29505233465694813, w0=0.22918820073487312, w1=-0.1884137608745713\n",
      "Gradient Descent(265/499): loss=0.29476474676038217, w0=0.22824624183594272, w1=-0.18802738822417828\n",
      "Gradient Descent(266/499): loss=0.29447884724861373, w0=0.22730667498562468, w1=-0.18763750666020057\n",
      "Gradient Descent(267/499): loss=0.29419462168184324, w0=0.22636948484044273, w1=-0.1872441728189895\n",
      "Gradient Descent(268/499): loss=0.293912055798884, w0=0.2254346562032092, w1=-0.1868474426030098\n",
      "Gradient Descent(269/499): loss=0.29363113551432113, w0=0.22450217402150788, w1=-0.18644737118991822\n",
      "Gradient Descent(270/499): loss=0.29335184691572797, w0=0.22357202338619186, w1=-0.18604401304154392\n",
      "Gradient Descent(271/499): loss=0.2930741762609335, w0=0.22264418952989665, w1=-0.18563742191277172\n",
      "Gradient Descent(272/499): loss=0.2927981099753431, w0=0.22171865782556785, w1=-0.18522765086032844\n",
      "Gradient Descent(273/499): loss=0.2925236346493099, w0=0.22079541378500384, w1=-0.1848147522514731\n",
      "Gradient Descent(274/499): loss=0.2922507370355548, w0=0.21987444305741263, w1=-0.18439877777259156\n",
      "Gradient Descent(275/499): loss=0.2919794040466378, w0=0.2189557314279834, w1=-0.18397977843769636\n",
      "Gradient Descent(276/499): loss=0.2917096227524734, w0=0.21803926481647207, w1=-0.18355780459683216\n",
      "Gradient Descent(277/499): loss=0.29144138037789574, w0=0.21712502927580085, w1=-0.18313290594438764\n",
      "Gradient Descent(278/499): loss=0.29117466430026645, w0=0.21621301099067208, w1=-0.1827051315273144\n",
      "Gradient Descent(279/499): loss=0.29090946204712836, w0=0.21530319627619549, w1=-0.18227452975325373\n",
      "Gradient Descent(280/499): loss=0.29064576129390257, w0=0.2143955715765293, w1=-0.18184114839857146\n",
      "Gradient Descent(281/499): loss=0.2903835498616273, w0=0.2134901234635348, w1=-0.18140503461630222\n",
      "Gradient Descent(282/499): loss=0.29012281571473914, w0=0.21258683863544428, w1=-0.1809662349440031\n",
      "Gradient Descent(283/499): loss=0.2898635469588937, w0=0.2116857039155423, w1=-0.18052479531151797\n",
      "Gradient Descent(284/499): loss=0.2896057318388273, w0=0.2107867062508601, w1=-0.18008076104865287\n",
      "Gradient Descent(285/499): loss=0.2893493587362564, w0=0.20988983271088288, w1=-0.17963417689276306\n",
      "Gradient Descent(286/499): loss=0.2890944161678154, w0=0.2089950704862701, w1=-0.1791850869962529\n",
      "Gradient Descent(287/499): loss=0.2888408927830325, w0=0.20810240688758866, w1=-0.17873353493398855\n",
      "Gradient Descent(288/499): loss=0.2885887773623398, w0=0.20721182934405832, w1=-0.17827956371062503\n",
      "Gradient Descent(289/499): loss=0.28833805881512115, w0=0.2063233254023103, w1=-0.17782321576784743\n",
      "Gradient Descent(290/499): loss=0.28808872617779396, w0=0.20543688272515764, w1=-0.17736453299152805\n",
      "Gradient Descent(291/499): loss=0.2878407686119244, w0=0.2045524890903784, w1=-0.17690355671879907\n",
      "Gradient Descent(292/499): loss=0.2875941754023773, w0=0.20367013238951073, w1=-0.17644032774504242\n",
      "Gradient Descent(293/499): loss=0.2873489359554979, w0=0.20278980062666027, w1=-0.17597488633079686\n",
      "Gradient Descent(294/499): loss=0.2871050397973251, w0=0.2019114819173193, w1=-0.1755072722085836\n",
      "Gradient Descent(295/499): loss=0.28686247657183733, w0=0.20103516448719808, w1=-0.17503752458965052\n",
      "Gradient Descent(296/499): loss=0.2866212360392277, w0=0.2001608366710676, w1=-0.17456568217063653\n",
      "Gradient Descent(297/499): loss=0.2863813080742098, w0=0.19928848691161435, w1=-0.1740917831401558\n",
      "Gradient Descent(298/499): loss=0.28614268266435355, w0=0.19841810375830646, w1=-0.17361586518530375\n",
      "Gradient Descent(299/499): loss=0.2859053499084478, w0=0.19754967586627137, w1=-0.17313796549808427\n",
      "Gradient Descent(300/499): loss=0.28566930001489343, w0=0.19668319199518483, w1=-0.17265812078176013\n",
      "Gradient Descent(301/499): loss=0.2854345233001224, w0=0.19581864100817126, w1=-0.17217636725712615\n",
      "Gradient Descent(302/499): loss=0.2852010101870448, w0=0.19495601187071518, w1=-0.1716927406687071\n",
      "Gradient Descent(303/499): loss=0.2849687512035214, w0=0.19409529364958383, w1=-0.1712072762908795\n",
      "Gradient Descent(304/499): loss=0.28473773698086324, w0=0.1932364755117606, w1=-0.17072000893391995\n",
      "Gradient Descent(305/499): loss=0.28450795825235636, w0=0.19237954672338953, w1=-0.17023097294997858\n",
      "Gradient Descent(306/499): loss=0.28427940585181033, w0=0.1915244966487304, w1=-0.1697402022389805\n",
      "Gradient Descent(307/499): loss=0.28405207071213334, w0=0.19067131474912472, w1=-0.16924773025445414\n",
      "Gradient Descent(308/499): loss=0.28382594386392845, w0=0.1898199905819722, w1=-0.16875359000928844\n",
      "Gradient Descent(309/499): loss=0.28360101643411634, w0=0.18897051379971763, w1=-0.16825781408141888\n",
      "Gradient Descent(310/499): loss=0.28337727964457843, w0=0.18812287414884843, w1=-0.16776043461944354\n",
      "Gradient Descent(311/499): loss=0.2831547248108245, w0=0.18727706146890225, w1=-0.16726148334816954\n",
      "Gradient Descent(312/499): loss=0.28293334334068043, w0=0.18643306569148496, w1=-0.16676099157409083\n",
      "Gradient Descent(313/499): loss=0.282713126733, w0=0.18559087683929876, w1=-0.16625899019079787\n",
      "Gradient Descent(314/499): loss=0.2824940665763958, w0=0.18475048502518024, w1=-0.1657555096843201\n",
      "Gradient Descent(315/499): loss=0.2822761545479922, w0=0.18391188045114856, w1=-0.16525058013840155\n",
      "Gradient Descent(316/499): loss=0.28205938241219813, w0=0.18307505340746333, w1=-0.16474423123971085\n",
      "Gradient Descent(317/499): loss=0.28184374201950096, w0=0.1822399942716924, w1=-0.16423649228298562\n",
      "Gradient Descent(318/499): loss=0.28162922530527773, w0=0.18140669350778926, w1=-0.1637273921761127\n",
      "Gradient Descent(319/499): loss=0.28141582428862866, w0=0.18057514166518016, w1=-0.16321695944514422\n",
      "Gradient Descent(320/499): loss=0.2812035310712277, w0=0.1797453293778605, w1=-0.16270522223925077\n",
      "Gradient Descent(321/499): loss=0.2809923378361916, w0=0.17891724736350104, w1=-0.16219220833561185\n",
      "Gradient Descent(322/499): loss=0.2807822368469681, w0=0.1780908864225631, w1=-0.16167794514424477\n",
      "Gradient Descent(323/499): loss=0.28057322044624144, w0=0.1772662374374232, w1=-0.16116245971277218\n",
      "Gradient Descent(324/499): loss=0.28036528105485564, w0=0.17644329137150688, w1=-0.1606457787311294\n",
      "Gradient Descent(325/499): loss=0.28015841117075463, w0=0.17562203926843153, w1=-0.16012792853621174\n",
      "Gradient Descent(326/499): loss=0.27995260336793965, w0=0.17480247225115836, w1=-0.15960893511646293\n",
      "Gradient Descent(327/499): loss=0.27974785029544286, w0=0.1739845815211531, w1=-0.15908882411640493\n",
      "Gradient Descent(328/499): loss=0.2795441446763184, w0=0.17316835835755578, w1=-0.15856762084110995\n",
      "Gradient Descent(329/499): loss=0.2793414793066472, w0=0.17235379411635918, w1=-0.15804535026061547\n",
      "Gradient Descent(330/499): loss=0.2791398470545597, w0=0.17154088022959582, w1=-0.1575220370142826\n",
      "Gradient Descent(331/499): loss=0.27893924085927296, w0=0.17072960820453378, w1=-0.15699770541509867\n",
      "Gradient Descent(332/499): loss=0.2787396537301425, w0=0.16991996962288095, w1=-0.15647237945392456\n",
      "Gradient Descent(333/499): loss=0.27854107874573036, w0=0.16911195613999763, w1=-0.15594608280368755\n",
      "Gradient Descent(334/499): loss=0.27834350905288613, w0=0.16830555948411768, w1=-0.15541883882352\n",
      "Gradient Descent(335/499): loss=0.2781469378658435, w0=0.1675007714555778, w1=-0.154890670562845\n",
      "Gradient Descent(336/499): loss=0.27795135846533026, w0=0.166697583926055, w1=-0.15436160076540903\n",
      "Gradient Descent(337/499): loss=0.27775676419769263, w0=0.16589598883781242, w1=-0.15383165187326264\n",
      "Gradient Descent(338/499): loss=0.27756314847403263, w0=0.16509597820295294, w1=-0.15330084603068977\n",
      "Gradient Descent(339/499): loss=0.27737050476935876, w0=0.16429754410268088, w1=-0.15276920508808595\n",
      "Gradient Descent(340/499): loss=0.2771788266217504, w0=0.1635006786865716, w1=-0.15223675060578637\n",
      "Gradient Descent(341/499): loss=0.2769881076315356, w0=0.16270537417184885, w1=-0.15170350385784434\n",
      "Gradient Descent(342/499): loss=0.2767983414604784, w0=0.1619116228426701, w1=-0.15116948583576045\n",
      "Gradient Descent(343/499): loss=0.2766095218309832, w0=0.16111941704941918, w1=-0.1506347172521634\n",
      "Gradient Descent(344/499): loss=0.27642164252530765, w0=0.16032874920800672, w1=-0.1500992185444428\n",
      "Gradient Descent(345/499): loss=0.2762346973847889, w0=0.15953961179917822, w1=-0.1495630098783347\n",
      "Gradient Descent(346/499): loss=0.2760486803090828, w0=0.15875199736782933, w1=-0.1490261111514603\n",
      "Gradient Descent(347/499): loss=0.275863585255412, w0=0.15796589852232867, w1=-0.14848854199681846\n",
      "Gradient Descent(348/499): loss=0.27567940623782794, w0=0.1571813079338479, w1=-0.14795032178623255\n",
      "Gradient Descent(349/499): loss=0.2754961373264826, w0=0.15639821833569903, w1=-0.14741146963375215\n",
      "Gradient Descent(350/499): loss=0.27531377264691215, w0=0.15561662252267888, w1=-0.14687200439901038\n",
      "Gradient Descent(351/499): loss=0.27513230637933084, w0=0.15483651335042067, w1=-0.14633194469053695\n",
      "Gradient Descent(352/499): loss=0.27495173275793555, w0=0.15405788373475254, w1=-0.14579130886902814\n",
      "Gradient Descent(353/499): loss=0.27477204607022104, w0=0.1532807266510632, w1=-0.14525011505057325\n",
      "Gradient Descent(354/499): loss=0.2745932406563054, w0=0.15250503513367422, w1=-0.14470838110983955\n",
      "Gradient Descent(355/499): loss=0.2744153109082662, w0=0.15173080227521935, w1=-0.14416612468321427\n",
      "Gradient Descent(356/499): loss=0.2742382512694845, w0=0.1509580212260304, w1=-0.1436233631719063\n",
      "Gradient Descent(357/499): loss=0.27406205623400187, w0=0.15018668519352996, w1=-0.14308011374500615\n",
      "Gradient Descent(358/499): loss=0.2738867203458843, w0=0.14941678744163067, w1=-0.14253639334250637\n",
      "Gradient Descent(359/499): loss=0.2737122381985967, w0=0.14864832129014102, w1=-0.1419922186782814\n",
      "Gradient Descent(360/499): loss=0.273538604434387, w0=0.14788128011417753, w1=-0.14144760624302893\n",
      "Gradient Descent(361/499): loss=0.273365813743678, w0=0.1471156573435836, w1=-0.14090257230717138\n",
      "Gradient Descent(362/499): loss=0.27319386086447073, w0=0.14635144646235432, w1=-0.14035713292372023\n",
      "Gradient Descent(363/499): loss=0.27302274058175324, w0=0.14558864100806806, w1=-0.13981130393110142\n",
      "Gradient Descent(364/499): loss=0.27285244772692135, w0=0.14482723457132382, w1=-0.1392651009559443\n",
      "Gradient Descent(365/499): loss=0.27268297717720646, w0=0.144067220795185, w1=-0.1387185394158327\n",
      "Gradient Descent(366/499): loss=0.27251432385511104, w0=0.14330859337462903, w1=-0.13817163452202075\n",
      "Gradient Descent(367/499): loss=0.2723464827278541, w0=0.14255134605600348, w1=-0.13762440128211134\n",
      "Gradient Descent(368/499): loss=0.27217944880682376, w0=0.14179547263648745, w1=-0.13707685450270063\n",
      "Gradient Descent(369/499): loss=0.2720132171470376, w0=0.1410409669635596, w1=-0.1365290087919859\n",
      "Gradient Descent(370/499): loss=0.27184778284661204, w0=0.1402878229344714, w1=-0.13598087856234037\n",
      "Gradient Descent(371/499): loss=0.27168314104623853, w0=0.13953603449572657, w1=-0.13543247803285227\n",
      "Gradient Descent(372/499): loss=0.2715192869286672, w0=0.1387855956425661, w1=-0.13488382123183185\n",
      "Gradient Descent(373/499): loss=0.27135621571819984, w0=0.13803650041845889, w1=-0.1343349219992834\n",
      "Gradient Descent(374/499): loss=0.27119392268018655, w0=0.13728874291459803, w1=-0.13378579398934615\n",
      "Gradient Descent(375/499): loss=0.2710324031205344, w0=0.13654231726940277, w1=-0.13323645067270098\n",
      "Gradient Descent(376/499): loss=0.27087165238521976, w0=0.1357972176680256, w1=-0.13268690533894695\n",
      "Gradient Descent(377/499): loss=0.2707116658598086, w0=0.13505343834186528, w1=-0.13213717109894427\n",
      "Gradient Descent(378/499): loss=0.27055243896898434, w0=0.1343109735680847, w1=-0.13158726088712824\n",
      "Gradient Descent(379/499): loss=0.2703939671760824, w0=0.1335698176691346, w1=-0.13103718746379012\n",
      "Gradient Descent(380/499): loss=0.2702362459826299, w0=0.13282996501228195, w1=-0.13048696341732993\n",
      "Gradient Descent(381/499): loss=0.2700792709278948, w0=0.1320914100091442, w1=-0.1299366011664771\n",
      "Gradient Descent(382/499): loss=0.26992303758843916, w0=0.13135414711522803, w1=-0.12938611296248362\n",
      "Gradient Descent(383/499): loss=0.26976754157767957, w0=0.13061817082947377, w1=-0.12883551089128586\n",
      "Gradient Descent(384/499): loss=0.26961277854545396, w0=0.12988347569380432, w1=-0.12828480687563987\n",
      "Gradient Descent(385/499): loss=0.26945874417759497, w0=0.1291500562926796, w1=-0.12773401267722576\n",
      "Gradient Descent(386/499): loss=0.2693054341955089, w0=0.12841790725265537, w1=-0.12718313989872668\n",
      "Gradient Descent(387/499): loss=0.2691528443557606, w0=0.1276870232419476, w1=-0.12663219998587738\n",
      "Gradient Descent(388/499): loss=0.26900097044966426, w0=0.12695739897000088, w1=-0.12608120422948826\n",
      "Gradient Descent(389/499): loss=0.26884980830288124, w0=0.12622902918706239, w1=-0.12553016376743947\n",
      "Gradient Descent(390/499): loss=0.26869935377502185, w0=0.12550190868375988, w1=-0.12497908958665162\n",
      "Gradient Descent(391/499): loss=0.2685496027592536, w0=0.12477603229068504, w1=-0.12442799252502686\n",
      "Gradient Descent(392/499): loss=0.26840055118191525, w0=0.12405139487798075, w1=-0.12387688327336754\n",
      "Gradient Descent(393/499): loss=0.26825219500213604, w0=0.12332799135493372, w1=-0.1233257723772658\n",
      "Gradient Descent(394/499): loss=0.2681045302114604, w0=0.1226058166695707, w1=-0.12277467023897147\n",
      "Gradient Descent(395/499): loss=0.2679575528334775, w0=0.12188486580826023, w1=-0.12222358711923151\n",
      "Gradient Descent(396/499): loss=0.2678112589234569, w0=0.12116513379531776, w1=-0.1216725331391086\n",
      "Gradient Descent(397/499): loss=0.2676656445679886, w0=0.12044661569261622, w1=-0.12112151828177166\n",
      "Gradient Descent(398/499): loss=0.2675207058846287, w0=0.11972930659919974, w1=-0.1205705523942665\n",
      "Gradient Descent(399/499): loss=0.26737643902154906, w0=0.11901320165090297, w1=-0.12001964518925871\n",
      "Gradient Descent(400/499): loss=0.2672328401571935, w0=0.11829829601997328, w1=-0.11946880624675763\n",
      "Gradient Descent(401/499): loss=0.26708990549993716, w0=0.11758458491469853, w1=-0.11891804501581275\n",
      "Gradient Descent(402/499): loss=0.2669476312877518, w0=0.11687206357903754, w1=-0.11836737081619257\n",
      "Gradient Descent(403/499): loss=0.26680601378787533, w0=0.11616072729225622, w1=-0.11781679284003553\n",
      "Gradient Descent(404/499): loss=0.26666504929648527, w0=0.11545057136856612, w1=-0.11726632015348487\n",
      "Gradient Descent(405/499): loss=0.26652473413837835, w0=0.11474159115676871, w1=-0.11671596169829547\n",
      "Gradient Descent(406/499): loss=0.2663850646666531, w0=0.11403378203990178, w1=-0.11616572629342592\n",
      "Gradient Descent(407/499): loss=0.2662460372623979, w0=0.11332713943489178, w1=-0.11561562263660229\n",
      "Gradient Descent(408/499): loss=0.2661076483343824, w0=0.1126216587922079, w1=-0.11506565930586868\n",
      "Gradient Descent(409/499): loss=0.26596989431875384, w0=0.11191733559552224, w1=-0.11451584476110903\n",
      "Gradient Descent(410/499): loss=0.2658327716787376, w0=0.11121416536137141, w1=-0.11396618734555727\n",
      "Gradient Descent(411/499): loss=0.26569627690434133, w0=0.11051214363882442, w1=-0.11341669528727827\n",
      "Gradient Descent(412/499): loss=0.2655604065120645, w0=0.10981126600915153, w1=-0.11286737670063876\n",
      "Gradient Descent(413/499): loss=0.2654251570446095, w0=0.1091115280854998, w1=-0.1123182395877484\n",
      "Gradient Descent(414/499): loss=0.26529052507059975, w0=0.10841292551256897, w1=-0.11176929183989268\n",
      "Gradient Descent(415/499): loss=0.2651565071842994, w0=0.10771545396629445, w1=-0.11122054123893498\n",
      "Gradient Descent(416/499): loss=0.26502310000533724, w0=0.1070191091535302, w1=-0.11067199545871263\n",
      "Gradient Descent(417/499): loss=0.2648903001784361, w0=0.10632388681173902, w1=-0.110123662066401\n",
      "Gradient Descent(418/499): loss=0.26475810437314323, w0=0.10562978270868205, w1=-0.10957554852387377\n",
      "Gradient Descent(419/499): loss=0.26462650928356674, w0=0.10493679264211636, w1=-0.10902766218902978\n",
      "Gradient Descent(420/499): loss=0.26449551162811424, w0=0.10424491243949098, w1=-0.1084800103171188\n",
      "Gradient Descent(421/499): loss=0.2643651081492357, w0=0.10355413795765152, w1=-0.10793260006203206\n",
      "Gradient Descent(422/499): loss=0.26423529561316966, w0=0.10286446508254256, w1=-0.10738543847759448\n",
      "Gradient Descent(423/499): loss=0.2641060708096923, w0=0.1021758897289193, w1=-0.10683853251881963\n",
      "Gradient Descent(424/499): loss=0.2639774305518713, w0=0.10148840784005606, w1=-0.10629188904316966\n",
      "Gradient Descent(425/499): loss=0.2638493716758215, w0=0.10080201538746476, w1=-0.10574551481177545\n",
      "Gradient Descent(426/499): loss=0.26372189104046473, w0=0.10011670837060944, w1=-0.10519941649066523\n",
      "Gradient Descent(427/499): loss=0.2635949855272932, w0=0.09943248281663156, w1=-0.10465360065195069\n",
      "Gradient Descent(428/499): loss=0.26346865204013437, w0=0.09874933478007014, w1=-0.1041080737750254\n",
      "Gradient Descent(429/499): loss=0.26334288750492146, w0=0.0980672603425939, w1=-0.10356284224771743\n",
      "Gradient Descent(430/499): loss=0.26321768886946545, w0=0.09738625561272693, w1=-0.1030179123674589\n",
      "Gradient Descent(431/499): loss=0.2630930531032301, w0=0.09670631672558741, w1=-0.10247329034240554\n",
      "Gradient Descent(432/499): loss=0.2629689771971105, w0=0.09602743984261865, w1=-0.10192898229257846\n",
      "Gradient Descent(433/499): loss=0.26284545816321464, w0=0.09534962115133447, w1=-0.10138499425095127\n",
      "Gradient Descent(434/499): loss=0.262722493034648, w0=0.0946728568650552, w1=-0.10084133216456526\n",
      "Gradient Descent(435/499): loss=0.26260007886529974, w0=0.09399714322265978, w1=-0.10029800189558441\n",
      "Gradient Descent(436/499): loss=0.26247821272963373, w0=0.09332247648832655, w1=-0.09975500922238525\n",
      "Gradient Descent(437/499): loss=0.2623568917224808, w0=0.09264885295129192, w1=-0.09921235984058013\n",
      "Gradient Descent(438/499): loss=0.26223611295883464, w0=0.09197626892559571, w1=-0.09867005936408298\n",
      "Gradient Descent(439/499): loss=0.26211587357364957, w0=0.09130472074984658, w1=-0.09812811332610102\n",
      "Gradient Descent(440/499): loss=0.26199617072164255, w0=0.09063420478697143, w1=-0.09758652718017793\n",
      "Gradient Descent(441/499): loss=0.2618770015770948, w0=0.08996471742398768, w1=-0.09704530630115402\n",
      "Gradient Descent(442/499): loss=0.26175836333366026, w0=0.08929625507175654, w1=-0.09650445598618812\n",
      "Gradient Descent(443/499): loss=0.2616402532041726, w0=0.08862881416476212, w1=-0.09596398145568634\n",
      "Gradient Descent(444/499): loss=0.26152266842045757, w0=0.08796239116086825, w1=-0.09542388785430425\n",
      "Gradient Descent(445/499): loss=0.2614056062331457, w0=0.08729698254110455, w1=-0.0948841802518439\n",
      "Gradient Descent(446/499): loss=0.26128906391148915, w0=0.08663258480942633, w1=-0.09434486364423807\n",
      "Gradient Descent(447/499): loss=0.2611730387431802, w0=0.08596919449250798, w1=-0.09380594295441505\n",
      "Gradient Descent(448/499): loss=0.26105752803417176, w0=0.0853068081395054, w1=-0.09326742303326696\n",
      "Gradient Descent(449/499): loss=0.26094252910850113, w0=0.08464542232185696, w1=-0.09272930866048167\n",
      "Gradient Descent(450/499): loss=0.2608280393081152, w0=0.0839850336330479, w1=-0.09219160454549707\n",
      "Gradient Descent(451/499): loss=0.26071405599269853, w0=0.08332563868841926, w1=-0.09165431532829946\n",
      "Gradient Descent(452/499): loss=0.26060057653950297, w0=0.08266723412493375, w1=-0.091117445580366\n",
      "Gradient Descent(453/499): loss=0.2604875983431806, w0=0.08200981660099281, w1=-0.0905809998054283\n",
      "Gradient Descent(454/499): loss=0.2603751188156173, w0=0.08135338279620347, w1=-0.09004498244040586\n",
      "Gradient Descent(455/499): loss=0.2602631353857701, w0=0.08069792941120407, w1=-0.08950939785613315\n",
      "Gradient Descent(456/499): loss=0.2601516454995054, w0=0.0800434531674312, w1=-0.08897425035828697\n",
      "Gradient Descent(457/499): loss=0.2600406466194395, w0=0.0793899508069548, w1=-0.08843954418807524\n",
      "Gradient Descent(458/499): loss=0.25993013622478206, w0=0.07873741909224422, w1=-0.08790528352316157\n",
      "Gradient Descent(459/499): loss=0.2598201118111798, w0=0.07808585480601354, w1=-0.08737147247831323\n",
      "Gradient Descent(460/499): loss=0.2597105708905647, w0=0.0774352547509857, w1=-0.08683811510632683\n",
      "Gradient Descent(461/499): loss=0.2596015109910011, w0=0.07678561574974883, w1=-0.08630521539863266\n",
      "Gradient Descent(462/499): loss=0.2594929296565379, w0=0.07613693464451739, w1=-0.08577277728622565\n",
      "Gradient Descent(463/499): loss=0.2593848244470597, w0=0.0754892082970006, w1=-0.0852408046402225\n",
      "Gradient Descent(464/499): loss=0.25927719293814194, w0=0.07484243358815913, w1=-0.08470930127280314\n",
      "Gradient Descent(465/499): loss=0.25917003272090716, w0=0.07419660741808703, w1=-0.08417827093771614\n",
      "Gradient Descent(466/499): loss=0.25906334140188303, w0=0.07355172670576218, w1=-0.08364771733123656\n",
      "Gradient Descent(467/499): loss=0.2589571166028615, w0=0.07290778838894346, w1=-0.08311764409261438\n",
      "Gradient Descent(468/499): loss=0.25885135596076136, w0=0.07226478942391304, w1=-0.0825880548050556\n",
      "Gradient Descent(469/499): loss=0.2587460571274909, w0=0.0716227267853906, w1=-0.08205895299610717\n",
      "Gradient Descent(470/499): loss=0.25864121776981336, w0=0.07098159746626519, w1=-0.08153034213866962\n",
      "Gradient Descent(471/499): loss=0.2585368355692133, w0=0.07034139847752889, w1=-0.08100222565131049\n",
      "Gradient Descent(472/499): loss=0.25843290822176535, w0=0.06970212684799552, w1=-0.0804746068993181\n",
      "Gradient Descent(473/499): loss=0.25832943343800363, w0=0.06906377962425643, w1=-0.07994748919493412\n",
      "Gradient Descent(474/499): loss=0.258226408942794, w0=0.06842635387038289, w1=-0.07942087579845972\n",
      "Gradient Descent(475/499): loss=0.25812383247520715, w0=0.06778984666790736, w1=-0.07889476991839596\n",
      "Gradient Descent(476/499): loss=0.2580217017883929, w0=0.06715425511550575, w1=-0.07836917471261563\n",
      "Gradient Descent(477/499): loss=0.257920014649457, w0=0.06651957632900818, w1=-0.07784409328839785\n",
      "Gradient Descent(478/499): loss=0.25781876883933896, w0=0.06588580744105649, w1=-0.07731952870368149\n",
      "Gradient Descent(479/499): loss=0.25771796215269105, w0=0.06525294560114929, w1=-0.07679548396697745\n",
      "Gradient Descent(480/499): loss=0.2576175923977593, w0=0.06462098797526944, w1=-0.07627196203872273\n",
      "Gradient Descent(481/499): loss=0.257517657396266, w0=0.06398993174596902, w1=-0.07574896583105052\n",
      "Gradient Descent(482/499): loss=0.25741815498329246, w0=0.06335977411196031, w1=-0.0752264982092673\n",
      "Gradient Descent(483/499): loss=0.2573190830071658, w0=0.06273051228824769, w1=-0.07470456199145721\n",
      "Gradient Descent(484/499): loss=0.25722043932934374, w0=0.062102143505674307, w1=-0.074183159950109\n",
      "Gradient Descent(485/499): loss=0.2571222218243034, w0=0.0614746650111092, w1=-0.07366229481152603\n",
      "Gradient Descent(486/499): loss=0.2570244283794301, w0=0.06084807406694051, w1=-0.07314196925763522\n",
      "Gradient Descent(487/499): loss=0.25692705689490836, w0=0.06022236795132768, w1=-0.07262218592516838\n",
      "Gradient Descent(488/499): loss=0.2568301052836131, w0=0.05959754395763018, w1=-0.0721029474076915\n",
      "Gradient Descent(489/499): loss=0.25673357147100373, w0=0.05897359939473676, w1=-0.07158425625451635\n",
      "Gradient Descent(490/499): loss=0.2566374533950177, w0=0.05835053158641645, w1=-0.07106611497299581\n",
      "Gradient Descent(491/499): loss=0.25654174900596644, w0=0.05772833787173918, w1=-0.07054852602711625\n",
      "Gradient Descent(492/499): loss=0.2564464562664325, w0=0.057107015604333226, w1=-0.0700314918401142\n",
      "Gradient Descent(493/499): loss=0.2563515731511675, w0=0.056486562152914435, w1=-0.06951501479268969\n",
      "Gradient Descent(494/499): loss=0.2562570976469915, w0=0.05586697490043104, w1=-0.0689990972260103\n",
      "Gradient Descent(495/499): loss=0.25616302775269384, w0=0.05524825124472223, w1=-0.06848374143947393\n",
      "Gradient Descent(496/499): loss=0.25606936147893394, w0=0.054630388597527495, w1=-0.06796894969417953\n",
      "Gradient Descent(497/499): loss=0.2559760968481455, w0=0.05401338438529947, w1=-0.0674547242101529\n",
      "Gradient Descent(498/499): loss=0.25588323189443923, w0=0.05339723604805033, w1=-0.06694106717037966\n",
      "Gradient Descent(499/499): loss=0.2557907646635087, w0=0.052781941040348876, w1=-0.06642798071738987\n"
     ]
    }
   ],
   "source": [
    "w_logreg, loss_logreg = f.logistic_regression(y_train_train_lg, tX_train,np.ones(22),500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9097733667882285\n",
      "F1 score:  0.0506626763574177\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_logreg)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = np.where(y_pred == 1, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [ 0.05278194 -0.06642798  0.02117751 -0.00274513  0.49011676  0.18080126\n",
      " -0.32497592 -0.32600825 -0.52893756 -0.28400304 -0.42510498 -0.12187267\n",
      " -0.17498828 -0.1238623  -0.38370667  0.5267693   0.11758655  0.71558617\n",
      "  0.07128298  0.13220975  0.25721627  0.26162381] \n",
      " Loss =  0.2557907646635087 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.005704934219548543\n"
     ]
    }
   ],
   "source": [
    "y_test_logreg = tX_test.dot(w_logreg)\n",
    "y_test_logreg = np.where(y_test_logreg > 0.5, 1, 0)\n",
    "\n",
    "print('weights = \\n', w_logreg,'\\n Loss = ', loss_logreg,'\\n*****************************************************************************',\n",
    "        ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train== 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_logreg == 1)/len(y_test_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/99): loss=18.207806990644862, w0=0.9078319282799385, w1=0.9078341834706829\n",
      "Gradient Descent(1/99): loss=16.36117617190301, w0=0.8157561433011598, w1=0.815760581290357\n",
      "Gradient Descent(2/99): loss=14.516392331053625, w0=0.7237725585933471, w1=0.7237791043345082\n",
      "Gradient Descent(3/99): loss=12.67345441132835, w0=0.631881095434813, w1=0.6318896713945503\n",
      "Gradient Descent(4/99): loss=10.832366467881576, w0=0.5400817347412534, w1=0.5400922610999396\n",
      "Gradient Descent(5/99): loss=8.99317095889692, w0=0.4483749079165405, w1=0.44838730280129574\n",
      "Gradient Descent(6/99): loss=7.156198218760744, w0=0.35676443230285565, w1=0.35677861205126216\n",
      "Gradient Descent(7/99): loss=5.323926978543616, w0=0.26527949655879657, w1=0.26529537601322084\n",
      "Gradient Descent(8/99): loss=3.5145487817161682, w0=0.17413819403247968, w1=0.17415568688197136\n",
      "Gradient Descent(9/99): loss=1.8472306256148947, w0=0.0849185676753477, w1=0.0849375869953934\n",
      "Gradient Descent(10/99): loss=0.76013464705722, w0=0.007034012888014168, w1=0.00705447298405322\n",
      "Gradient Descent(11/99): loss=0.433963205495897, w0=-0.03801961898097428, w1=-0.037997793297615885\n",
      "Gradient Descent(12/99): loss=0.3550633524257237, w0=-0.059395762457870455, w1=-0.059372615247669694\n",
      "Gradient Descent(13/99): loss=0.3268701664643956, w0=-0.07182392028144263, w1=-0.07179947312691057\n",
      "Gradient Descent(14/99): loss=0.3142037708873347, w0=-0.08001247627934195, w1=-0.079986742265792\n",
      "Gradient Descent(15/99): loss=0.3077443906596993, w0=-0.08579004755469558, w1=-0.08576303574026925\n",
      "Gradient Descent(16/99): loss=0.3041813076570549, w0=-0.09004022281464975, w1=-0.09001193996657422\n",
      "Gradient Descent(17/99): loss=0.3021092235676002, w0=-0.09325407858780918, w1=-0.09322453002142955\n",
      "Gradient Descent(18/99): loss=0.30085785882845695, w0=-0.09573138023247815, w1=-0.09570057027760036\n",
      "Gradient Descent(19/99): loss=0.30008046677697126, w0=-0.09766765730650187, w1=-0.09763558959207405\n",
      "Gradient Descent(20/99): loss=0.2995867532858525, w0=-0.09919682328411746, w1=-0.09916350092392799\n",
      "Gradient Descent(21/99): loss=0.29926754749497875, w0=-0.10041403937238022, w1=-0.10037946509224192\n",
      "Gradient Descent(22/99): loss=0.2990580428160503, w0=-0.1013888826169315, w1=-0.10135305884506338\n",
      "Gradient Descent(23/99): loss=0.298918722349955, w0=-0.10217337218291402, w1=-0.1021363011160253\n",
      "Gradient Descent(24/99): loss=0.29882496711464757, w0=-0.10280709352670828, w1=-0.10276877717940722\n",
      "Gradient Descent(25/99): loss=0.2987611688262856, w0=-0.10332059830492861, w1=-0.10328103854732212\n",
      "Gradient Descent(26/99): loss=0.29871728703685646, w0=-0.10373773464723901, w1=-0.10369693323395236\n",
      "Gradient Descent(27/99): loss=0.29868678273989935, w0=-0.10407728894964188, w1=-0.10403524754247134\n",
      "Gradient Descent(28/99): loss=0.2986653512908656, w0=-0.10435417013316163, w1=-0.10431089031891959\n",
      "Gradient Descent(29/99): loss=0.29865013153744874, w0=-0.10458028122654278, w1=-0.10453576453121995\n",
      "Gradient Descent(30/99): loss=0.2986392048098995, w0=-0.10476517194730102, w1=-0.10471941984737361\n",
      "Gradient Descent(31/99): loss=0.29863127354479374, w0=-0.10491653452463882, w1=-0.10486954845614051\n",
      "Gradient Descent(32/99): loss=0.2986254529294177, w0=-0.10504058514547933, w1=-0.10499236651130886\n",
      "Gradient Descent(33/99): loss=0.2986211345708191, w0=-0.10514236052536162, w1=-0.10509291070118854\n",
      "Gradient Descent(34/99): loss=0.298617896565649, w0=-0.105225950556284, w1=-0.10517527089533396\n",
      "Gradient Descent(35/99): loss=0.29861544374292615, w0=-0.1052946821847646, w1=-0.10524277402170543\n",
      "Gradient Descent(36/99): loss=0.2986135676866159, w0=-0.10535126566138835, w1=-0.10529813031549141\n",
      "Gradient Descent(37/99): loss=0.29861211981771707, w0=-0.10539791147567054, w1=-0.10534355025338632\n",
      "Gradient Descent(38/99): loss=0.2986109931544409, w0=-0.10543642426301437, w1=-0.10538083846007341\n",
      "Gradient Descent(39/99): loss=0.29861010987337877, w0=-0.1054682784940297, w1=-0.10541146939715798\n",
      "Gradient Descent(40/99): loss=0.2986094127704096, w0=-0.10549467966511666, w1=-0.10543664855343743\n",
      "Gradient Descent(41/99): loss=0.2986088593577876, w0=-0.10551661389163278, w1=-0.10545736203781286\n",
      "Gradient Descent(42/99): loss=0.2986084177532454, w0=-0.10553488818495926, w1=-0.10547441685614704\n",
      "Gradient Descent(43/99): loss=0.2986080637943373, w0=-0.10555016321942932, w1=-0.10548847367802253\n",
      "Gradient Descent(44/99): loss=0.29860777899563967, w0=-0.10556298002704874, w1=-0.10550007353132328\n",
      "Gradient Descent(45/99): loss=0.2986075490895667, w0=-0.10557378177053149, w1=-0.10550965957515666\n",
      "Gradient Descent(46/99): loss=0.2986073629741543, w0=-0.10558293151902733, w1=-0.10551759487548804\n",
      "Gradient Descent(47/99): loss=0.2986072119468119, w0=-0.10559072677181225, w1=-0.10552417692875515\n",
      "Gradient Descent(48/99): loss=0.29860708914066614, w0=-0.1055974113325643, w1=-0.10552964953608168\n",
      "Gradient Descent(49/99): loss=0.2986069891057099, w0=-0.1056031850226847, w1=-0.10553421251654736\n",
      "Gradient Descent(50/99): loss=0.298606907494404, w0=-0.10560821163039397, w1=-0.10553802965624225\n",
      "Gradient Descent(51/99): loss=0.29860684082337363, w0=-0.10561262541836705, w1=-0.10554123521586777\n",
      "Gradient Descent(52/99): loss=0.2986067862910868, w0=-0.10561653645286408, w1=-0.10554393925983929\n",
      "Gradient Descent(53/99): loss=0.29860674163713585, w0=-0.1056200349688307, w1=-0.10554623202136357\n",
      "Gradient Descent(54/99): loss=0.2986067050327514, w0=-0.10562319494606805, w1=-0.10554818747858984\n",
      "Gradient Descent(55/99): loss=0.2986066749949876, w0=-0.10562607703953639, w1=-0.105549866284898\n",
      "Gradient Descent(56/99): loss=0.2986066503190157, w0=-0.10562873098075715, w1=-0.10555131817028804\n",
      "Gradient Descent(57/99): loss=0.29860663002439697, w0=-0.10563119754599315, w1=-0.10555258390954984\n",
      "Gradient Descent(58/99): loss=0.2986066133122244, w0=-0.10563351016950513, w1=-0.10555369693551124\n",
      "Gradient Descent(59/99): loss=0.29860659953079255, w0=-0.10563569626598676, w1=-0.105554684661466\n",
      "Gradient Descent(60/99): loss=0.29860658814798663, w0=-0.10563777831466936, w1=-0.10555556956527291\n",
      "Gradient Descent(61/99): loss=0.29860657872900653, w0=-0.10563977474809251, w1=-0.10555637007812162\n",
      "Gradient Descent(62/99): loss=0.29860657091834836, w0=-0.10564170068076512, w1=-0.10555710131318988\n",
      "Gradient Descent(63/99): loss=0.2986065644251919, w0=-0.10564356850658078, w1=-0.10555777566305581\n",
      "Gradient Descent(64/99): loss=0.2986065590115302, w0=-0.10564538838864027, w1=-0.1055584032895177\n",
      "Gradient Descent(65/99): loss=0.2986065544825108, w0=-0.10564716866086704, w1=-0.10555899252520749\n",
      "Gradient Descent(66/99): loss=0.2986065506785648, w0=-0.10564891615730666, w1=-0.10555955020288842\n",
      "Gradient Descent(67/99): loss=0.2986065474689867, w0=-0.10565063648213521, w1=-0.10556008192546197\n",
      "Gradient Descent(68/99): loss=0.2986065447466932, w0=-0.10565233423105524, w1=-0.10556059228736274\n",
      "Gradient Descent(69/99): loss=0.29860654242393936, w0=-0.10565401317283298, w1=-0.10556108505609459\n",
      "Gradient Descent(70/99): loss=0.29860654042881685, w0=-0.10565567639815397, w1=-0.10556156332108559\n",
      "Gradient Descent(71/99): loss=0.2986065387023894, w0=-0.10565732644168199, w1=-0.1055620296157462\n",
      "Gradient Descent(72/99): loss=0.2986065371963486, w0=-0.10565896538214509, w1=-0.10556248601755489\n",
      "Gradient Descent(73/99): loss=0.2986065358710945, w0=-0.10566059492440502, w1=-0.105562934230127\n",
      "Gradient Descent(74/99): loss=0.2986065346941635, w0=-0.1056622164667534, w1=-0.10556337565051067\n",
      "Gradient Descent(75/99): loss=0.2986065336389407, w0=-0.10566383115609432, w1=-0.10556381142436906\n",
      "Gradient Descent(76/99): loss=0.2986065326836064, w0=-0.10566543993319341, w1=-0.10556424249122927\n",
      "Gradient Descent(77/99): loss=0.2986065318102705, w0=-0.10566704356978224, w1=-0.10556466962158646\n",
      "Gradient Descent(78/99): loss=0.29860653100426476, w0=-0.10566864269898386, w1=-0.1055650934473293\n",
      "Gradient Descent(79/99): loss=0.29860653025356204, w0=-0.10567023784026167, w1=-0.10556551448668859\n",
      "Gradient Descent(80/99): loss=0.2986065295483014, w0=-0.10567182941987754, w1=-0.10556593316469544\n",
      "Gradient Descent(81/99): loss=0.2986065288803966, w0=-0.10567341778766738, w1=-0.10556634982995658\n",
      "Gradient Descent(82/99): loss=0.29860652824321743, w0=-0.10567500323079732, w1=-0.10556676476841062\n",
      "Gradient Descent(83/99): loss=0.2986065276313275, w0=-0.10567658598504363, w1=-0.10556717821460779\n",
      "Gradient Descent(84/99): loss=0.29860652704026824, w0=-0.10567816624404264, w1=-0.10556759036095985\n",
      "Gradient Descent(85/99): loss=0.29860652646638464, w0=-0.10567974416687506, w1=-0.10556800136532442\n",
      "Gradient Descent(86/99): loss=0.2986065259066787, w0=-0.10568131988428585, w1=-0.10556841135722471\n",
      "Gradient Descent(87/99): loss=0.2986065253586922, w0=-0.10568289350378415, w1=-0.10556882044294952\n",
      "Gradient Descent(88/99): loss=0.2986065248204095, w0=-0.1056844651138252, w1=-0.10556922870973509\n",
      "Gradient Descent(89/99): loss=0.29860652429017803, w0=-0.10568603478723979, w1=-0.10556963622919452\n",
      "Gradient Descent(90/99): loss=0.2986065237666415, w0=-0.1056876025840462, w1=-0.10557004306012975\n",
      "Gradient Descent(91/99): loss=0.29860652324868864, w0=-0.10568916855375615, w1=-0.10557044925083743\n",
      "Gradient Descent(92/99): loss=0.2986065227354079, w0=-0.10569073273726555, w1=-0.10557085484099968\n",
      "Gradient Descent(93/99): loss=0.29860652222605133, w0=-0.10569229516840514, w1=-0.10557125986323476\n",
      "Gradient Descent(94/99): loss=0.2986065217200061, w0=-0.10569385587521168, w1=-0.10557166434436821\n",
      "Gradient Descent(95/99): loss=0.298606521216769, w0=-0.1056954148809708, w1=-0.10557206830647567\n",
      "Gradient Descent(96/99): loss=0.29860652071592764, w0=-0.10569697220507158, w1=-0.10557247176773756\n",
      "Gradient Descent(97/99): loss=0.2986065202171438, w0=-0.10569852786370783, w1=-0.1055728747431402\n",
      "Gradient Descent(98/99): loss=0.29860651972013974, w0=-0.10570008187045281, w1=-0.10557327724505067\n",
      "Gradient Descent(99/99): loss=0.298606519224688, w0=-0.10570163423673071, w1=-0.10557367928368819\n",
      "Gradient Descent(100/99): loss=0.2986065187306014, w0=-0.10570318497220306, w1=-0.10557408086751058\n"
     ]
    }
   ],
   "source": [
    "w_reg_logreg, loss_reg_logreg = f.reg_logistic_regression(y_train_processed_logreg, tX_train, 0.01, initial_w, 100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [-0.10570318 -0.10557408 -0.10551638 -0.10546428 -0.10539099 -0.10547108\n",
      " -0.10545289 -0.10547108 -0.10555219 -0.10543358 -0.10580189 -0.10591579\n",
      " -0.10548113 -0.10543551 -0.10544656 -0.10545656 -0.10594989 -0.10540836\n",
      " -0.10546825 -0.10540809 -0.10538928 -0.10540574] \n",
      " Loss =  0.2986065187306014 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.0\n"
     ]
    }
   ],
   "source": [
    "y_test_reg_logreg = tX_test.dot(w_reg_logreg)\n",
    "y_test_reg_logreg = np.where(y_test_reg_logreg > 0.5, 1, 0)\n",
    "\n",
    "print('weights = \\n', w_reg_logreg,'\\n Loss = ', loss_reg_logreg,'\\n*****************************************************************************',\n",
    "        ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_reg_logreg == 1)/len(y_test_reg_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = np.where(y_test_reg_logreg == 1, 1, -1)\n",
    "h.create_csv_submission(test_ids, y_sub, 'submission_reg_logreg6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
