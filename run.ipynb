{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "try:\n",
    "    import importlib\n",
    "    importlib.reload(h)\n",
    "    importlib.reload(f)\n",
    "    importlib.reload(d)\n",
    "except NameError: # It hasn't been imported yet\n",
    "    import helpers as h\n",
    "    import implementations as f\n",
    "    import data_processing as d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and feature selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For this to work, the data folder needs to be one level above the project folder and the folder name needs\n",
    "#to be 'data'\n",
    "data_folder = '../data/'\n",
    "x_train, x_test, y_train, train_ids, test_ids = h.load_csv_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = h.load_csv_data(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/y_train.npy', y_train)\n",
    "np.save('../data/x_train.npy', x_train)\n",
    "np.save('../data/x_test.npy', x_test)\n",
    "np.save('../data/train_ids.npy', train_ids)\n",
    "np.save('../data/test_ids.npy', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"../data/x_train.npy\")\n",
    "x_test = np.load(\"../data/x_test.npy\")\n",
    "y_train = np.load(\"../data/y_train.npy\")\n",
    "train_ids = np.load(\"../data/trains_ids.npy\")\n",
    "test_ids = np.load(\"../data/test_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE',\n",
       "       'SEQNO', '_PSU', 'CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES',\n",
       "       'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1',\n",
       "       'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE',\n",
       "       'HHADULT', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH',\n",
       "       'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BPMEDS',\n",
       "       'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW',\n",
       "       'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2',\n",
       "       'CHCKIDNY', 'DIABETE3', 'DIABAGE2', 'SEX', 'MARITAL', 'EDUCA',\n",
       "       'RENTHOM1', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'VETERAN3',\n",
       "       'EMPLOY1', 'CHILDREN', 'INCOME2', 'INTERNET', 'WEIGHT2', 'HEIGHT3',\n",
       "       'PREGNANT', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK',\n",
       "       'DIFFDRES', 'DIFFALON', 'SMOKE100', 'SMOKDAY2', 'STOPSMK2',\n",
       "       'LASTSMK2', 'USENOW3', 'ALCDAY5', 'AVEDRNK2', 'DRNK3GE5',\n",
       "       'MAXDRNKS', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG',\n",
       "       'VEGETAB1', 'EXERANY2', 'EXRACT11', 'EXEROFT1', 'EXERHMM1',\n",
       "       'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'STRENGTH', 'LMTJOIN3',\n",
       "       'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'SEATBELT', 'FLUSHOT6',\n",
       "       'FLSHTMY2', 'IMFVPLAC', 'PNEUVAC3', 'HIVTST6', 'HIVTSTD3',\n",
       "       'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR',\n",
       "       'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM',\n",
       "       'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1',\n",
       "       'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2',\n",
       "       'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2',\n",
       "       'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2',\n",
       "       'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL',\n",
       "       'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE',\n",
       "       'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM',\n",
       "       'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1',\n",
       "       'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART',\n",
       "       'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU',\n",
       "       'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG',\n",
       "       'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2',\n",
       "       'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3',\n",
       "       'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1',\n",
       "       'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN',\n",
       "       'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD',\n",
       "       'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2',\n",
       "       'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR',\n",
       "       'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK',\n",
       "       'ADMOVE', 'MISTMNT', 'ADANXEV', 'QSTVER', 'QSTLANG', 'MSCODE',\n",
       "       '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_CHISPNC', '_CRACE1',\n",
       "       '_CPRACE', '_CLLCPWT', '_DUALUSE', '_DUALCOR', '_LLCPWT',\n",
       "       '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL',\n",
       "       '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1',\n",
       "       '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1',\n",
       "       '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4',\n",
       "       'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG',\n",
       "       '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_',\n",
       "       '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_',\n",
       "       'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN',\n",
       "       '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM',\n",
       "       '_FRTLT1', '_VEGLT1', '_FRT16', '_VEG23', '_FRUITEX', '_VEGETEX',\n",
       "       '_TOTINDA', 'METVL11_', 'METVL21_', 'MAXVO2_', 'FC60_', 'ACTIN11_',\n",
       "       'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_',\n",
       "       '_MINAC11', '_MINAC21', 'STRFREQ_', 'PAMISS1_', 'PAMIN11_',\n",
       "       'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_',\n",
       "       '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021',\n",
       "       '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1',\n",
       "       '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_FLSHOT6', '_PNEUMO2',\n",
       "       '_AIDTST3'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_named all the features names and remove the ID column\n",
    "features_name = np.genfromtxt('../data/x_train.csv', delimiter=',', dtype=str, max_rows=1)[1:] \n",
    "features_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "one paper on internet suggests to use these features : \n",
    "\n",
    " _RFHYPE5, TOLDHI2, _CHOLCHK, _BMI5, SMOKE100, CVDSTRK3, DIABETE3, _TOTINDA, _FRTLT1, _VEGLT1, _RFDRHV5, HLTHPLN1, MEDCOST, GENHLTH, MENTHLTH, PHYSHLTH, DIFFWALK, SEX, _AGEG5YR, EDUCA, and INCOME2\n",
    "\n",
    " then, iterating through them, it removes the missing values, made the data binary when possible, removed the 'don't know, not sure', and ordinal (categorical) variables ares changed to 0,1,2,..., and renamed them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a mask to get important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the important features\n",
    "features_list = ['_RFHYPE5', 'TOLDHI2', '_CHOLCHK', '_BMI5', 'SMOKE100', 'CVDSTRK3', 'DIABETE3', '_TOTINDA', '_FRTLT1', '_VEGLT1', '_RFDRHV5', \n",
    "                 'HLTHPLN1', 'MEDCOST', 'GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'DIFFWALK', 'SEX', '_AGEG5YR', 'EDUCA', 'INCOME2']\n",
    "\n",
    "def masking(X, features_list):\n",
    "     #INPUT: X = (x_train, x_test), features_list: features wanted\n",
    "\n",
    "    #Create a mask to filter the data\n",
    "    mask = np.isin(features_name, features_list)\n",
    "    x_train, x_test = X\n",
    "\n",
    "    x_train_featured = x_train[:, mask]\n",
    "    x_test_featured = x_test[:, mask]\n",
    "    \n",
    "    return x_train_featured, x_test_featured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove all missing values on X and remove corresponding lines in Y and ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all missing values on X and remove corresponding lines in Y and ids\n",
    "def cleanMissingValues(X): \n",
    "    x, y, ids = X\n",
    "    x_clean = x[~np.isnan(x).any(axis=1)]\n",
    "    #x_test_featured_clean = x_test_featured[~np.isnan(x_test_featured).any(axis=1)]\n",
    "\n",
    "    y_clean = y[~np.isnan(x).any(axis=1)]\n",
    "\n",
    "    ids_clean = ids[~np.isnan(x).any(axis=1)]\n",
    "    #test_ids_filtered = test_ids[~np.isnan(x_test_featured).any(axis=1)]\n",
    "    \n",
    "    return x_clean, y_clean, ids_clean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values by the mean of the column for the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replaceMissingValuesMean(X):\n",
    "    #compute the mean of the column\n",
    "    mean = np.nanmean(X, axis = 0)\n",
    "\n",
    "    #replace all the NaN values by the mean\n",
    "    X = np.where(np.isnan(X), mean, X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing [Necessary] \n",
    "For this to work, Masking has to be done aswell\n",
    "### We want to clean the data for each feature, making them binary for yes/no, etc... and rename them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data Processing \n",
    "\n",
    "def featureProcessing(dataMasked):\n",
    "    \n",
    "    x_train, x_test = dataMasked\n",
    "    \n",
    "    x_train_processed = d.feature_processing_test(x_train)\n",
    "\n",
    "    #Test data Processing \n",
    "    x_test_processed = d.feature_processing_test(x_test)\n",
    "    \n",
    "    return x_train_processed, x_test_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can apply the processing functions to the data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainMask, testMask = masking((x_train, x_test), features_list)\n",
    "\n",
    "trainProcessed, testProcessed = featureProcessing((trainMask ,testMask))\n",
    "\n",
    "x_train_algo = replaceMissingValuesMean(trainProcessed)\n",
    "x_test_algo = replaceMissingValuesMean(testProcessed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the preprocessing has been done, we can format the data to be used by the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_train = np.c_[np.ones((len(x_train_algo), 1)), x_train_algo]\n",
    "tX_test = np.c_[np.ones((len(x_test_algo), 1)), x_test_algo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_w = [random.choice([1, -1]) for i in range(len(tX_train[0]))]\n",
    "initial_w = np.ones(len(tX_train[0]))\n",
    "max_iter = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation of the dataset in a test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tX_train_train = tX_train[:int(len(tX_train)*0.7)]\n",
    "y_train_train = y_train[:int(len(tX_train)*0.7)]\n",
    "tX_train_test = tX_train[int(len(tX_train)*0.7):]\n",
    "y_train_test = y_train[int(len(tX_train)*0.7):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_progression(w):\n",
    "    # Plot progression of the weights in function of the iteration and progression on the test set\n",
    "    plt.figure(0)\n",
    "    plt.plot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And then, we can run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossMSE(weights, loss, y, x ):\n",
    "    loss_test_set = []\n",
    "\n",
    "    for w in weights:\n",
    "        loss_test_set.append(f.compute_mse(y, x, w))\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.semilogy(loss)\n",
    "    plt.semilogy(loss_test_set)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MSE gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(999/1000): Final loss=0.16322289498404216\n"
     ]
    }
   ],
   "source": [
    "#Compute gradient descent with MSE as loss function (see functions.py for the function)\n",
    "\n",
    "w_mse_gd, loss_mse_gd = f.mean_squared_error_gd(y_train_train, tX_train_train, initial_w, 1000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_test_set = []\n",
    "\n",
    "for w in w_mse_gd:\n",
    "    loss_test_set.append(f.compute_mse(y_train_test, tX_train_test, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.semilogy(loss_mse_gd)\n",
    "plt.semilogy(loss_test_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8680631037880557\n",
      "F1 score:  0.11981566820276497\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_mse_gd[-1])\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "print(\"F1 score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#h.create_csv_submission(test_ids, y_test_rounded, 'submission_gd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      "\n",
      " [ 9.20167666e-02 -7.71490238e-02  5.86797876e-03 -8.43936422e-04\n",
      "  3.83395852e-01  1.22940270e-01 -1.21100642e-01 -1.21896949e-01\n",
      " -1.67716021e-01 -8.54598525e-02 -9.62527225e-02 -2.57862282e-02\n",
      " -7.42547553e-02 -5.06910131e-02 -1.16309687e-01  2.50926875e-01\n",
      " -1.51153836e-04  7.01061785e-01  1.05783835e-02 -3.64603987e-02\n",
      "  7.86555181e-02  6.24983197e-02] \n",
      "\n",
      " Loss =  0.16322289498404216 \n",
      "\n",
      "*****************************************************************************  \n",
      "\n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.008813391967379479\n"
     ]
    }
   ],
   "source": [
    "#Test the model on the test sample. Do we need to standardize ?\n",
    "\n",
    "y_test = tX_test.dot(w_mse_gd[-1])\n",
    "y_test_rounded = np.where(y_test > 0, 1, -1) #not sure about this line\n",
    "\n",
    "print('weights = \\n\\n', w_mse_gd[-1],'\\n\\n Loss = ', loss_mse_gd[-1],'\\n\\n*****************************************************************************',\n",
    "      ' \\n\\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_rounded == 1)/len(y_test_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run some cross validation to see the best initial weights (as a function of the proportion of 1, -1 and 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MSE SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 1999/1999: loss=0.5308156725767825, w0=0.6727209105777945, w1=0.19167095489707042\n"
     ]
    }
   ],
   "source": [
    "w_mse_sgd, loss_mse_sgd = f.mean_squared_error_sgd(y_train_train, tX_train_train, initial_w, 2000, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossMSE(weights, loss, y, x ):\n",
    "    loss_test_set = []\n",
    "\n",
    "    for w in weights:\n",
    "        loss_test_set.append(f.compute_mse(y, x, w))\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.semilogy(loss)\n",
    "    plt.semilogy(loss_test_set)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mse_gd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLossMSE(w_mse_sgd, loss_mse_sgd, y_train_test, tX_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5536311089891407\n",
      "F1 score:  0.08754698174720187\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_mse_sgd[-1])\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [ 0.67272091  0.19167095  0.01685251 -0.06640884  0.93035369  0.71186752\n",
      "  0.72274045  0.66111226  0.37007749  0.77780544 -0.50236852 -0.54662024\n",
      "  0.69056636  0.80070849  0.70249968  0.77342045 -0.31979801  0.9077714\n",
      "  0.69292927  0.79724999  0.87622862  0.88066828] \n",
      " Loss =  0.5308156725767825 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.40006765466862926\n"
     ]
    }
   ],
   "source": [
    "y_test_sgd = tX_test.dot(w_mse_sgd[-1])\n",
    "y_test_rounded_sgd = np.where(y_test_sgd > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_mse_sgd[-1],'\\n Loss = ', loss_mse_sgd[-1],'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_rounded_sgd == 1)/len(y_test_rounded_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ls, loss_ls = f.least_squares(y_train_train, tX_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9117034568929613\n",
      "F1 score:  0.03529411764705882\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_ls)\n",
    "y_pred = np.where(y_pred > 0, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [-3.54515184e-01  5.76100349e-02  2.15645760e-03 -1.88754185e-04\n",
      " -3.22325550e-02 -9.15316093e-03 -9.19649704e-02 -3.69989496e-01\n",
      " -4.77401102e-02 -9.79382213e-02 -2.50199111e-03 -5.79831694e-03\n",
      " -1.02170381e-01 -4.18711437e-02 -7.19620069e-02  3.78987972e-02\n",
      "  1.72309041e-02 -2.14401256e-01  2.99498822e-02 -5.64090919e-03\n",
      " -5.15795614e-03 -9.86993155e-03] \n",
      " Loss =  0.1368442031431572 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.0025873339489298677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_ls = tX_test.dot(w_ls)\n",
    "y_test_ls = np.where(y_test_ls > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_ls,'\\n Loss = ', loss_ls,'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_ls == 1)/len(y_test_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ridge, loss_ridge = f.ridge_regression(y_train, tX_train, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.zeros(max_iters)\n",
    "    weights = np.zeros((max_iters, tx.shape[1]))\n",
    "\n",
    "for l in np.arange(1*10**-6, 1, 7):\n",
    "    w, l = f.ridge_regression(y_train, tX_train, l)\n",
    "    weights.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [-0.16601266  0.0391845   0.00262514 -0.00060561 -0.04657832 -0.03076275\n",
      " -0.09248568 -0.30124959 -0.06110316 -0.09897353 -0.01768843 -0.00966822\n",
      " -0.11207717 -0.04410244 -0.080523    0.01857876  0.0155675  -0.07562154\n",
      " -0.02572875 -0.01541715 -0.01049847 -0.01446916] \n",
      " Loss =  0.13790402252250836 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.0013165232814342789\n"
     ]
    }
   ],
   "source": [
    "y_test_ridge = tX_test.dot(w_ridge)\n",
    "y_test_ridge = np.where(y_test_ridge > 0, 1, -1)\n",
    "\n",
    "print('weights = \\n', w_ridge,'\\n Loss = ', loss_ridge,'\\n*****************************************************************************',\n",
    "      ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_ridge == 1)/len(y_test_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed_logreg = np.where(y_train == 1, 1, 0)\n",
    "y_train_train_lg = np.where(y_train == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/499): loss=22.228996654053788, w0=0.9088302070838765, w1=0.774412574698857\n",
      "Gradient Descent(1/499): loss=9.61084201026568, w0=0.8176604155043729, w1=0.5488251519014856\n",
      "Gradient Descent(2/499): loss=1.2867255420662551, w0=0.7266421871872321, w1=0.32357539293222454\n",
      "Gradient Descent(3/499): loss=1.0905883795901203, w0=0.7117199546655477, w1=0.2920885638054991\n",
      "Gradient Descent(4/499): loss=1.0210100359812195, w0=0.7050808937172566, w1=0.28412765397195483\n",
      "Gradient Descent(5/499): loss=0.9651652376027849, w0=0.6994507601948652, w1=0.278115964176346\n",
      "Gradient Descent(6/499): loss=0.9197144055840988, w0=0.6942364853647579, w1=0.2724105456807827\n",
      "Gradient Descent(7/499): loss=0.8819968488611999, w0=0.6892588720382995, w1=0.26657257268688056\n",
      "Gradient Descent(8/499): loss=0.8496388889807243, w0=0.6844978206127393, w1=0.26067571485396496\n",
      "Gradient Descent(9/499): loss=0.8210060145414425, w0=0.6799487327086798, w1=0.25484484750932557\n",
      "Gradient Descent(10/499): loss=0.7951040217852328, w0=0.6755849725208484, w1=0.249113935940798\n",
      "Gradient Descent(11/499): loss=0.7713515359665011, w0=0.6713697498934519, w1=0.24345873032886653\n",
      "Gradient Descent(12/499): loss=0.7494096795901417, w0=0.6672673860063033, w1=0.2378364426793095\n",
      "Gradient Descent(13/499): loss=0.7290755831625568, w0=0.6632475025900957, w1=0.2322040413503875\n",
      "Gradient Descent(14/499): loss=0.7102190838766337, w0=0.6592860070030585, w1=0.2265254969927776\n",
      "Gradient Descent(15/499): loss=0.692745805596571, w0=0.6553649419997979, w1=0.22077442268544475\n",
      "Gradient Descent(16/499): loss=0.676576178201523, w0=0.6514719117024028, w1=0.21493458526323436\n",
      "Gradient Descent(17/499): loss=0.6616342797072854, w0=0.6475993288182219, w1=0.2089992932488281\n",
      "Gradient Descent(18/499): loss=0.647842809464743, w0=0.6437435780033998, w1=0.20297013234649522\n",
      "Gradient Descent(19/499): loss=0.635121795846666, w0=0.6399041496115419, w1=0.19685533099109942\n",
      "Gradient Descent(20/499): loss=0.623389384207351, w0=0.6360827929449089, w1=0.1906679767495537\n",
      "Gradient Descent(21/499): loss=0.6125635564866648, w0=0.6322827372493871, w1=0.18442427204588502\n",
      "Gradient Descent(22/499): loss=0.6025640324595581, w0=0.6285080207423088, w1=0.1781419768057557\n",
      "Gradient Descent(23/499): loss=0.5933139242956089, w0=0.6247629526502221, w1=0.17183913179676116\n",
      "Gradient Descent(24/499): loss=0.5847409568670526, w0=0.6210517151890292, w1=0.1655331001862011\n",
      "Gradient Descent(25/499): loss=0.5767782244571997, w0=0.6173780966253809, w1=0.15923991796877862\n",
      "Gradient Descent(26/499): loss=0.5693645410870319, w0=0.6137453359617621, w1=0.15297391286305892\n",
      "Gradient Descent(27/499): loss=0.5624444760001757, w0=0.6101560549399754, w1=0.14674753637950025\n",
      "Gradient Descent(28/499): loss=0.555968168282745, w0=0.6066122528961309, w1=0.14057135155582678\n",
      "Gradient Descent(29/499): loss=0.5498910013794829, w0=0.6031153428421574, w1=0.1344541246579954\n",
      "Gradient Descent(30/499): loss=0.5441731999821561, w0=0.5996662114025926, w1=0.1284029787730974\n",
      "Gradient Descent(31/499): loss=0.5387793941059661, w0=0.5962652897309951, w1=0.12242357768678022\n",
      "Gradient Descent(32/499): loss=0.5336781805121261, w0=0.5929126265713481, w1=0.11652031798431452\n",
      "Gradient Descent(33/499): loss=0.5288417004868587, w0=0.5896079579042603, w1=0.11069651514263773\n",
      "Gradient Descent(34/499): loss=0.5242452449930134, w0=0.5863507700691968, w1=0.10495457531736498\n",
      "Gradient Descent(35/499): loss=0.5198668927310021, w0=0.583140354966551, w1=0.09929614874355833\n",
      "Gradient Descent(36/499): loss=0.515687183038433, w0=0.5799758570594333, w1=0.09372226347684744\n",
      "Gradient Descent(37/499): loss=0.5116888232839957, w0=0.576856312564932, w1=0.08823343994306376\n",
      "Gradient Descent(38/499): loss=0.5078564290573236, w0=0.5737806815811889, w1=0.082829787745558\n",
      "Gradient Descent(39/499): loss=0.5041762947208729, w0=0.5707478740459333, w1=0.07751108664685245\n",
      "Gradient Descent(40/499): loss=0.5006361915588474, w0=0.567756770442852, w1=0.07227685378116619\n",
      "Gradient Descent(41/499): loss=0.49722519068417714, w0=0.5648062381195136, w1=0.06712639909902564\n",
      "Gradient Descent(42/499): loss=0.493933507947066, w0=0.5618951439912112, w1=0.06205887088441573\n",
      "Gradient Descent(43/499): loss=0.4907523682604691, w0=0.5590223643021898, w1=0.05707329297679117\n",
      "Gradient Descent(44/499): loss=0.48767388697493824, w0=0.556186792012964, w1=0.05216859511033524\n",
      "Gradient Descent(45/499): loss=0.48469096616926993, w0=0.5533873422872144, w1=0.04734363757147744\n",
      "Gradient Descent(46/499): loss=0.48179720395672493, w0=0.550622956467468, w1=0.04259723118330369\n",
      "Gradient Descent(47/499): loss=0.4789868151289123, w0=0.5478926048564071, w1=0.037928153456386865\n",
      "Gradient Descent(48/499): loss=0.47625456166508795, w0=0.5451952885598427, w1=0.03333516160037008\n",
      "Gradient Descent(49/499): loss=0.47359569182108274, w0=0.5425300405970531, w1=0.028817002967992344\n",
      "Gradient Descent(50/499): loss=0.471005886678723, w0=0.5398959264430092, w1=0.024372423400850007\n",
      "Gradient Descent(51/499): loss=0.4684812131839921, w0=0.5372920441335753, w1=0.020000173861391666\n",
      "Gradient Descent(52/499): loss=0.4660180828315545, w0=0.5347175240378191, w1=0.015699015665826023\n",
      "Gradient Descent(53/499): loss=0.46361321526614924, w0=0.5321715283799103, w1=0.011467724575359058\n",
      "Gradient Descent(54/499): loss=0.4612636061694697, w0=0.5296532505757665, w1=0.007305093956327766\n",
      "Gradient Descent(55/499): loss=0.45896649888613217, w0=0.5271619144357677, w1=0.003209937181524153\n",
      "Gradient Descent(56/499): loss=0.45671935931580665, w0=0.5246967732738415, w1=-0.0008189105862442224\n",
      "Gradient Descent(57/499): loss=0.4545198536619885, w0=0.5222571089544439, w1=-0.004782591112821596\n",
      "Gradient Descent(58/499): loss=0.45236582868256475, w0=0.5198422309019854, w1=-0.008682222218898531\n",
      "Gradient Descent(59/499): loss=0.4502552941344505, w0=0.5174514750917116, w1=-0.012518897236061581\n",
      "Gradient Descent(60/499): loss=0.44818640714517616, w0=0.5150842030366486, w1=-0.01629368472895682\n",
      "Gradient Descent(61/499): loss=0.4461574582792965, w0=0.5127398007817374, w1=-0.020007628431234485\n",
      "Gradient Descent(62/499): loss=0.44416685909766584, w0=0.5104176779135213, w1=-0.023661747352296\n",
      "Gradient Descent(63/499): loss=0.4422131310336495, w0=0.5081172665915672, w1=-0.02725703601954296\n",
      "Gradient Descent(64/499): loss=0.4402948954328104, w0=0.5058380206060815, w1=-0.030794464827137647\n",
      "Gradient Descent(65/499): loss=0.4384108646220318, w0=0.5035794144648271, w1=-0.03427498046747667\n",
      "Gradient Descent(66/499): loss=0.43655983389082464, w0=0.5013409425113865, w1=-0.03769950642585458\n",
      "Gradient Descent(67/499): loss=0.434740674282115, w0=0.4991221180759894, w1=-0.041068943522319594\n",
      "Gradient Descent(68/499): loss=0.43295232610242024, w0=0.49692247265948036, w1=-0.0443841704876317\n",
      "Gradient Descent(69/499): loss=0.4311937930722552, w0=0.4947415551505099, w1=-0.04764604456263431\n",
      "Gradient Descent(70/499): loss=0.42946413704713526, w0=0.49257893107565504, w1=-0.05085540211233484\n",
      "Gradient Descent(71/499): loss=0.4277624732478118, w0=0.49043418188189547, w1=-0.05401305924762817\n",
      "Gradient Descent(72/499): loss=0.4260879659455984, w0=0.48830690425066153, w1=-0.057119812448952915\n",
      "Gradient Descent(73/499): loss=0.42443982455493423, w0=0.48619670944252336, w1=-0.06017643918728998\n",
      "Gradient Descent(74/499): loss=0.4228173000908439, w0=0.4841032226714864, w1=-0.06318369853883919\n",
      "Gradient Descent(75/499): loss=0.4212196819537594, w0=0.4820260825077938, w1=-0.0661423317904746\n",
      "Gradient Descent(76/499): loss=0.41964629500839734, w0=0.4799649403080964, w1=-0.06905306303371066\n",
      "Gradient Descent(77/499): loss=0.4180964969270872, w0=0.477919459671839, w1=-0.07191659974543227\n",
      "Gradient Descent(78/499): loss=0.41656967577120063, w0=0.47588931592270894, w1=-0.07473363335407117\n",
      "Gradient Descent(79/499): loss=0.41506524778720016, w0=0.4738741956140094, w1=-0.0775048397902637\n",
      "Gradient Descent(80/499): loss=0.413582655396353, w0=0.47187379605684465, w1=-0.08023088002131483\n",
      "Gradient Descent(81/499): loss=0.41212136535937843, w0=0.4698878248700325, w1=-0.0829124005690304\n",
      "Gradient Descent(82/499): loss=0.4106808670992829, w0=0.467915999550698, w1=-0.08555003401067279\n",
      "Gradient Descent(83/499): loss=0.40926067116736187, w0=0.46595804706453964, w1=-0.0881443994629525\n",
      "Gradient Descent(84/499): loss=0.4078603078389125, w0=0.46401370345480175, w1=-0.09069610304909519\n",
      "Gradient Descent(85/499): loss=0.4064793258265659, w0=0.4620827134690292, w1=-0.09320573834912568\n",
      "Gradient Descent(86/499): loss=0.40511729110036243, w0=0.46016483020272203, w1=-0.0956738868335918\n",
      "Gradient Descent(87/499): loss=0.40377378580479245, w0=0.45825981475905214, w1=-0.09810111828101518\n",
      "Gradient Descent(88/499): loss=0.40244840726398123, w0=0.4563674359238439, w1=-0.10048799117940609\n",
      "Gradient Descent(89/499): loss=0.40114076706706825, w0=0.4544874698550621, w1=-0.1028350531122176\n",
      "Gradient Descent(90/499): loss=0.3998504902265934, w0=0.45261969978609085, w1=-0.10514284112914316\n",
      "Gradient Descent(91/499): loss=0.3985772144034089, w0=0.4507639157421226, w1=-0.10741188210218171\n",
      "Gradient Descent(92/499): loss=0.39732058919223145, w0=0.44891991426901573, w1=-0.10964269306740934\n",
      "Gradient Descent(93/499): loss=0.3960802754625279, w0=0.44708749817401117, w1=-0.11183578155290456\n",
      "Gradient Descent(94/499): loss=0.3948559447499072, w0=0.4452664762777331, w1=-0.11399164589327893\n",
      "Gradient Descent(95/499): loss=0.3936472786936484, w0=0.4434566631769299, w1=-0.11611077553126532\n",
      "Gradient Descent(96/499): loss=0.392453968516394, w0=0.4416578790174404, w1=-0.11819365130681454\n",
      "Gradient Descent(97/499): loss=0.391275714542403, w0=0.4398699492768995, w1=-0.12024074573414595\n",
      "Gradient Descent(98/499): loss=0.39011222575108356, w0=0.4380927045567229, w1=-0.1222525232671922\n",
      "Gradient Descent(99/499): loss=0.3889632193628203, w0=0.4363259803829365, w1=-0.12422944055387017\n",
      "Gradient Descent(100/499): loss=0.38782842045438237, w0=0.434569617015439, w1=-0.12617194667960163\n",
      "Gradient Descent(101/499): loss=0.3867075616014352, w0=0.4328234592653077, w1=-0.12808048340049752\n",
      "Gradient Descent(102/499): loss=0.38560038254589996, w0=0.43108735631978046, w1=-0.1299554853666093\n",
      "Gradient Descent(103/499): loss=0.384506629886105, w0=0.429361161574564, w1=-0.1317973803356407\n",
      "Gradient Descent(104/499): loss=0.38342605678784936, w0=0.4276447324731382, w1=-0.1336065893775013\n",
      "Gradient Descent(105/499): loss=0.3823584227146675, w0=0.42593793035274374, w1=-0.13538352707007323\n",
      "Gradient Descent(106/499): loss=0.3813034931757262, w0=0.42424062029675536, w1=-0.13712860168655006\n",
      "Gradient Descent(107/499): loss=0.3802610394899258, w0=0.42255267099316024, w1=-0.13884221537469618\n",
      "Gradient Descent(108/499): loss=0.3792308385648985, w0=0.42087395459887295, w1=-0.14052476432836386\n",
      "Gradient Descent(109/499): loss=0.37821267268970693, w0=0.4192043466096339, w1=-0.14217663895159333\n",
      "Gradient Descent(110/499): loss=0.3772063293401498, w0=0.4175437257352496, w1=-0.14379822401561101\n",
      "Gradient Descent(111/499): loss=0.37621160099567735, w0=0.4158919737799459, w1=-0.14538989880902972\n",
      "Gradient Descent(112/499): loss=0.37522828496699673, w0=0.41424897552761525, w1=-0.14695203728154427\n",
      "Gradient Descent(113/499): loss=0.37425618323353294, w0=0.41261461863175125, w1=-0.1484850081814051\n",
      "Gradient Descent(114/499): loss=0.3732951022899779, w0=0.41098879350987205, w1=-0.1499891751869431\n",
      "Gradient Descent(115/499): loss=0.3723448530012243, w0=0.4093713932422443, w1=-0.15146489703240804\n",
      "Gradient Descent(116/499): loss=0.3714052504650421, w0=0.40776231347472836, w1=-0.1529125276283736\n",
      "Gradient Descent(117/499): loss=0.3704761138819085, w0=0.40616145232557294, w1=-0.15433241617695306\n",
      "Gradient Descent(118/499): loss=0.3695572664314519, w0=0.4045687102959958, w1=-0.15572490728205954\n",
      "Gradient Descent(119/499): loss=0.36864853515501467, w0=0.4029839901843942, w1=-0.15709034105493663\n",
      "Gradient Descent(120/499): loss=0.36774975084388456, w0=0.40140719700403615, w1=-0.1584290532151759\n",
      "Gradient Descent(121/499): loss=0.36686074793277607, w0=0.39983823790408946, w1=-0.15974137518742984\n",
      "Gradient Descent(122/499): loss=0.3659813643981847, w0=0.39827702209385213, w1=-0.1610276341940203\n",
      "Gradient Descent(123/499): loss=0.3651114416612643, w0=0.39672346077005405, w1=-0.16228815334363444\n",
      "Gradient Descent(124/499): loss=0.3642508244949079, w0=0.39517746704710444, w1=-0.16352325171629303\n",
      "Gradient Descent(125/499): loss=0.3633993609347415, w0=0.39363895589016595, w1=-0.1647332444447677\n",
      "Gradient Descent(126/499): loss=0.36255690219375836, w0=0.3921078440509401, w1=-0.1659184427926173\n",
      "Gradient Descent(127/499): loss=0.36172330258035323, w0=0.3905840500060553, w1=-0.16707915422900602\n",
      "Gradient Descent(128/499): loss=0.3608984194195261, w0=0.3890674938979507, w1=-0.1682156825004591\n",
      "Gradient Descent(129/499): loss=0.3600821129770522, w0=0.38755809747815656, w1=-0.16932832769970596\n",
      "Gradient Descent(130/499): loss=0.35927424638642674, w0=0.3860557840528729, w1=-0.1704173863317535\n",
      "Gradient Descent(131/499): loss=0.35847468557841256, w0=0.38456047843075425, w1=-0.17148315137732686\n",
      "Gradient Descent(132/499): loss=0.3576832992130272, w0=0.383072106872811, w1=-0.1725259123538086\n",
      "Gradient Descent(133/499): loss=0.35689995861382834, w0=0.3815905970443422, w1=-0.17354595537380144\n",
      "Gradient Descent(134/499): loss=0.3561245377043581, w0=0.3801158779688166, w1=-0.17454356320143505\n",
      "Gradient Descent(135/499): loss=0.3553569129466278, w0=0.3786478799836245, w1=-0.17551901530653044\n",
      "Gradient Descent(136/499): loss=0.3545969632815246, w0=0.377186534697623, w1=-0.17647258791673234\n",
      "Gradient Descent(137/499): loss=0.3538445700710408, w0=0.375731774950403, w1=-0.1774045540677132\n",
      "Gradient Descent(138/499): loss=0.3530996170422252, w0=0.37428353477320736, w1=-0.1783151836515488\n",
      "Gradient Descent(139/499): loss=0.3523619902327747, w0=0.37284174935143316, w1=-0.17920474346336074\n",
      "Gradient Descent(140/499): loss=0.3516315779381775, w0=0.3714063549886533, w1=-0.18007349724631588\n",
      "Gradient Descent(141/499): loss=0.35090827066033986, w0=0.369977289072096, w1=-0.18092170573506944\n",
      "Gradient Descent(142/499): loss=0.3501919610576232, w0=0.368554490039521, w1=-0.1817496266977341\n",
      "Gradient Descent(143/499): loss=0.3494825438962308, w0=0.3671378973474375, w1=-0.18255751497645306\n",
      "Gradient Descent(144/499): loss=0.3487799160028824, w0=0.3657274514406061, w1=-0.1833456225266519\n",
      "Gradient Descent(145/499): loss=0.34808397621872667, w0=0.3643230937227735, w1=-0.18411419845503985\n",
      "Gradient Descent(146/499): loss=0.3473946253544363, w0=0.36292476652858874, w1=-0.184863489056428\n",
      "Gradient Descent(147/499): loss=0.34671176614644317, w0=0.3615324130966516, w1=-0.1855937378494285\n",
      "Gradient Descent(148/499): loss=0.3460353032142684, w0=0.3601459775436464, w1=-0.1863051856110953\n",
      "Gradient Descent(149/499): loss=0.34536514301890753, w0=0.35876540483951624, w1=-0.1869980704105643\n",
      "Gradient Descent(150/499): loss=0.34470119382223324, w0=0.35739064078363375, w1=-0.1876726276417477\n",
      "Gradient Descent(151/499): loss=0.34404336564738086, w0=0.35602163198192704, w1=-0.1883290900551342\n",
      "Gradient Descent(152/499): loss=0.3433915702400843, w0=0.35465832582492085, w1=-0.18896768778874462\n",
      "Gradient Descent(153/499): loss=0.34274572103093126, w0=0.3533006704666537, w1=-0.1895886483982889\n",
      "Gradient Descent(154/499): loss=0.3421057330985095, w0=0.3519486148044351, w1=-0.19019219688656921\n",
      "Gradient Descent(155/499): loss=0.34147152313341683, w0=0.3506021084594064, w1=-0.19077855573217053\n",
      "Gradient Descent(156/499): loss=0.3408430094031108, w0=0.34926110175787156, w1=-0.19134794491747817\n",
      "Gradient Descent(157/499): loss=0.34022011171757144, w0=0.3479255457133651, w1=-0.1919005819560594\n",
      "Gradient Descent(158/499): loss=0.3396027513957585, w0=0.34659539200942563, w1=-0.19243668191944477\n",
      "Gradient Descent(159/499): loss=0.33899085123283657, w0=0.34527059298304513, w1=-0.1929564574633416\n",
      "Gradient Descent(160/499): loss=0.33838433546815344, w0=0.34395110160876424, w1=-0.19346011885331202\n",
      "Gradient Descent(161/499): loss=0.3377831297539471, w0=0.34263687148338684, w1=-0.19394787398994368\n",
      "Gradient Descent(162/499): loss=0.3371871611247662, w0=0.3413278568112861, w1=-0.19441992843354247\n",
      "Gradient Descent(163/499): loss=0.3365963579675856, w0=0.34002401239027735, w1=-0.19487648542837213\n",
      "Gradient Descent(164/499): loss=0.33601064999259855, w0=0.33872529359803283, w1=-0.19531774592646625\n",
      "Gradient Descent(165/499): loss=0.33542996820467286, w0=0.33743165637901446, w1=-0.19574390861103522\n",
      "Gradient Descent(166/499): loss=0.33485424487544946, w0=0.33614305723190263, w1=-0.1961551699194904\n",
      "Gradient Descent(167/499): loss=0.3342834135160754, w0=0.33485945319749927, w1=-0.19655172406610533\n",
      "Gradient Descent(168/499): loss=0.33371740885055107, w0=0.33358080184708394, w1=-0.19693376306433383\n",
      "Gradient Descent(169/499): loss=0.33315616678968, w0=0.33230706127120385, w1=-0.1973014767488021\n",
      "Gradient Descent(170/499): loss=0.33259962440560875, w0=0.3310381900688779, w1=-0.19765505279699247\n",
      "Gradient Descent(171/499): loss=0.3320477199069402, w0=0.32977414733719745, w1=-0.19799467675063384\n",
      "Gradient Descent(172/499): loss=0.33150039261441167, w0=0.3285148926613055, w1=-0.19832053203681402\n",
      "Gradient Descent(173/499): loss=0.3309575829371216, w0=0.3272603861047381, w1=-0.1986327999888272\n",
      "Gradient Descent(174/499): loss=0.33041923234929527, w0=0.3260105882001117, w1=-0.19893165986676997\n",
      "Gradient Descent(175/499): loss=0.3298852833675769, w0=0.3247654599401411, w1=-0.19921728887789714\n",
      "Gradient Descent(176/499): loss=0.32935567952883626, w0=0.3235249627689737, w1=-0.1994898621967492\n",
      "Gradient Descent(177/499): loss=0.32883036536847876, w0=0.32228905857382534, w1=-0.1997495529850612\n",
      "Gradient Descent(178/499): loss=0.3283092863992481, w0=0.32105770967690517, w1=-0.199996532411463\n",
      "Gradient Descent(179/499): loss=0.3277923890905113, w0=0.31983087882761574, w1=-0.2002309696709797\n",
      "Gradient Descent(180/499): loss=0.32727962084801426, w0=0.31860852919501675, w1=-0.20045303200434056\n",
      "Gradient Descent(181/499): loss=0.3267709299940991, w0=0.31739062436054066, w1=-0.2006628847171042\n",
      "Gradient Descent(182/499): loss=0.32626626574837164, w0=0.31617712831094835, w1=-0.20086069119860703\n",
      "Gradient Descent(183/499): loss=0.32576557820881075, w0=0.31496800543151476, w1=-0.20104661294074141\n",
      "Gradient Descent(184/499): loss=0.32526881833330795, w0=0.31376322049943406, w1=-0.20122080955656999\n",
      "Gradient Descent(185/499): loss=0.3247759379216309, w0=0.3125627386774343, w1=-0.20138343879878118\n",
      "Gradient Descent(186/499): loss=0.32428688959779717, w0=0.31136652550759253, w1=-0.2015346565779917\n",
      "Gradient Descent(187/499): loss=0.3238016267928529, w0=0.3101745469053414, w1=-0.20167461698089995\n",
      "Gradient Descent(188/499): loss=0.32332010372804615, w0=0.30898676915365847, w1=-0.20180347228829548\n",
      "Gradient Descent(189/499): loss=0.3228422753983844, w0=0.30780315889743026, w1=-0.2019213729929278\n",
      "Gradient Descent(190/499): loss=0.32236809755657164, w0=0.30662368313798344, w1=-0.20202846781723854\n",
      "Gradient Descent(191/499): loss=0.3218975266973123, w0=0.3054483092277755, w1=-0.20212490373096006\n",
      "Gradient Descent(192/499): loss=0.3214305200419756, w0=0.30427700486523773, w1=-0.2022108259685836\n",
      "Gradient Descent(193/499): loss=0.32096703552361344, w0=0.3031097380897643, w1=-0.20228637804669977\n",
      "Gradient Descent(194/499): loss=0.32050703177232137, w0=0.3019464772768404, w1=-0.2023517017812134\n",
      "Gradient Descent(195/499): loss=0.320050468100937, w0=0.3007871911333034, w1=-0.2024069373044358\n",
      "Gradient Descent(196/499): loss=0.3195973044910661, w0=0.29963184869273185, w1=-0.20245222308205535\n",
      "Gradient Descent(197/499): loss=0.319147501579431, w0=0.2984804193109558, w1=-0.20248769592998936\n",
      "Gradient Descent(198/499): loss=0.31870102064453204, w0=0.2973328726616838, w1=-0.2025134910311176\n",
      "Gradient Descent(199/499): loss=0.3182578235936165, w0=0.2961891787322409, w1=-0.20252974195190018\n",
      "Gradient Descent(200/499): loss=0.31781787294994646, w0=0.2950493078194139, w1=-0.2025365806588798\n",
      "Gradient Descent(201/499): loss=0.31738113184035915, w0=0.2939132305253981, w1=-0.20253413753507057\n",
      "Gradient Descent(202/499): loss=0.3169475639831139, w0=0.29278091775384146, w1=-0.20252254139623355\n",
      "Gradient Descent(203/499): loss=0.316517133676017, w0=0.291652340705983, w1=-0.20250191950704025\n",
      "Gradient Descent(204/499): loss=0.31608980578482027, w0=0.2905274708768797, w1=-0.202472397597125\n",
      "Gradient Descent(205/499): loss=0.31566554573188477, w0=0.2894062800517198, w1=-0.2024340998770261\n",
      "Gradient Descent(206/499): loss=0.3152443194851045, w0=0.2882887403022181, w1=-0.20238714905401733\n",
      "Gradient Descent(207/499): loss=0.3148260935470853, w0=0.28717482398308963, w1=-0.20233166634782915\n",
      "Gradient Descent(208/499): loss=0.31441083494456884, w0=0.28606450372859904, w1=-0.20226777150626082\n",
      "Gradient Descent(209/499): loss=0.31399851121810046, w0=0.2849577524491825, w1=-0.2021955828206834\n",
      "Gradient Descent(210/499): loss=0.31358909041193195, w0=0.2838545433281386, w1=-0.20211521714143366\n",
      "Gradient Descent(211/499): loss=0.31318254106415544, w0=0.2827548498183861, w1=-0.20202678989309952\n",
      "Gradient Descent(212/499): loss=0.3127788321970612, w0=0.2816586456392859, w1=-0.2019304150896969\n",
      "Gradient Descent(213/499): loss=0.31237793330771574, w0=0.2805659047735238, w1=-0.20182620534973778\n",
      "Gradient Descent(214/499): loss=0.31197981435875344, w0=0.2794766014640528, w1=-0.20171427191119037\n",
      "Gradient Descent(215/499): loss=0.31158444576937727, w0=0.27839071021109213, w1=-0.20159472464633035\n",
      "Gradient Descent(216/499): loss=0.3111917984065644, w0=0.2773082057691805, w1=-0.20146767207648403\n",
      "Gradient Descent(217/499): loss=0.3108018435764686, w0=0.2762290631442823, w1=-0.20133322138666268\n",
      "Gradient Descent(218/499): loss=0.3104145530160195, w0=0.2751532575909438, w1=-0.2011914784400888\n",
      "Gradient Descent(219/499): loss=0.31002989888470806, w0=0.2740807646094985, w1=-0.20104254779261338\n",
      "Gradient Descent(220/499): loss=0.30964785375656084, w0=0.2730115599433194, w1=-0.2008865327070247\n",
      "Gradient Descent(221/499): loss=0.30926839061229094, w0=0.2719456195761159, w1=-0.20072353516724822\n",
      "Gradient Descent(222/499): loss=0.30889148283162693, w0=0.27088291972927514, w1=-0.2005536558924378\n",
      "Gradient Descent(223/499): loss=0.3085171041858125, w0=0.26982343685924476, w1=-0.20037699435095774\n",
      "Gradient Descent(224/499): loss=0.3081452288302739, w0=0.26876714765495674, w1=-0.20019364877425588\n",
      "Gradient Descent(225/499): loss=0.3077758312974506, w0=0.2677140290352903, w1=-0.20000371617062757\n",
      "Gradient Descent(226/499): loss=0.3074088864897859, w0=0.2666640581465729, w1=-0.19980729233887012\n",
      "Gradient Descent(227/499): loss=0.3070443696728709, w0=0.26561721236011804, w1=-0.19960447188182837\n",
      "Gradient Descent(228/499): loss=0.30668225646874314, w0=0.26457346926979847, w1=-0.1993953482198303\n",
      "Gradient Descent(229/499): loss=0.30632252284933, w0=0.26353280668965395, w1=-0.19918001360401366\n",
      "Gradient Descent(230/499): loss=0.30596514513003953, w0=0.2624952026515325, w1=-0.19895855912954263\n",
      "Gradient Descent(231/499): loss=0.30561009996348804, w0=0.2614606354027638, w1=-0.1987310747487152\n",
      "Gradient Descent(232/499): loss=0.30525736433336975, w0=0.26042908340386445, w1=-0.19849764928396066\n",
      "Gradient Descent(233/499): loss=0.3049069155484557, w0=0.25940052532627306, w1=-0.19825837044072767\n",
      "Gradient Descent(234/499): loss=0.3045587312367269, w0=0.25837494005011585, w1=-0.19801332482026257\n",
      "Gradient Descent(235/499): loss=0.3042127893396314, w0=0.2573523066620004, w1=-0.1977625979322781\n",
      "Gradient Descent(236/499): loss=0.30386906810647013, w0=0.2563326044528377, w1=-0.19750627420751238\n",
      "Gradient Descent(237/499): loss=0.3035275460888993, w0=0.2553158129156917, w1=-0.1972444370101786\n",
      "Gradient Descent(238/499): loss=0.30318820213555414, w0=0.2543019117436554, w1=-0.19697716865030498\n",
      "Gradient Descent(239/499): loss=0.30285101538678655, w0=0.25329088082775236, w1=-0.1967045503959655\n",
      "Gradient Descent(240/499): loss=0.3025159652695162, w0=0.2522827002548643, w1=-0.19642666248540105\n",
      "Gradient Descent(241/499): loss=0.30218303149219106, w0=0.251277350305683, w1=-0.19614358413903196\n",
      "Gradient Descent(242/499): loss=0.30185219403985397, w0=0.2502748114526862, w1=-0.19585539357136078\n",
      "Gradient Descent(243/499): loss=0.30152343316931585, w0=0.24927506435813748, w1=-0.19556216800276674\n",
      "Gradient Descent(244/499): loss=0.30119672940442915, w0=0.2482780898721086, w1=-0.19526398367119122\n",
      "Gradient Descent(245/499): loss=0.3008720635314612, w0=0.24728386903052493, w1=-0.19496091584371486\n",
      "Gradient Descent(246/499): loss=0.3005494165945651, w0=0.24629238305323273, w1=-0.19465303882802631\n",
      "Gradient Descent(247/499): loss=0.3002287698913444, w0=0.24530361334208794, w1=-0.19434042598378298\n",
      "Gradient Descent(248/499): loss=0.2999101049685112, w0=0.24431754147906634, w1=-0.19402314973386398\n",
      "Gradient Descent(249/499): loss=0.2995934036176333, w0=0.24333414922439442, w1=-0.19370128157551547\n",
      "Gradient Descent(250/499): loss=0.2992786478709709, w0=0.24235341851470055, w1=-0.19337489209138892\n",
      "Gradient Descent(251/499): loss=0.29896581999739663, w0=0.24137533146118625, w1=-0.19304405096047245\n",
      "Gradient Descent(252/499): loss=0.2986549024984024, w0=0.24039987034781712, w1=-0.19270882696891536\n",
      "Gradient Descent(253/499): loss=0.2983458781041857, w0=0.23942701762953297, w1=-0.19236928802074682\n",
      "Gradient Descent(254/499): loss=0.2980387297698167, w0=0.23845675593047702, w1=-0.19202550114848818\n",
      "Gradient Descent(255/499): loss=0.297733440671483, w0=0.23748906804224368, w1=-0.19167753252366035\n",
      "Gradient Descent(256/499): loss=0.2974299942028113, w0=0.23652393692214477, w1=-0.19132544746718547\n",
      "Gradient Descent(257/499): loss=0.29712837397126113, w0=0.23556134569149376, w1=-0.1909693104596846\n",
      "Gradient Descent(258/499): loss=0.29682856379459366, w0=0.23460127763390784, w1=-0.19060918515167039\n",
      "Gradient Descent(259/499): loss=0.2965305476974092, w0=0.23364371619362745, w1=-0.1902451343736367\n",
      "Gradient Descent(260/499): loss=0.2962343099077553, w0=0.23268864497385316, w1=-0.1898772201460441\n",
      "Gradient Descent(261/499): loss=0.2959398348538007, w0=0.2317360477350996, w1=-0.18950550368920338\n",
      "Gradient Descent(262/499): loss=0.29564710716057685, w0=0.23078590839356602, w1=-0.18913004543305573\n",
      "Gradient Descent(263/499): loss=0.29535611164678266, w0=0.22983821101952367, w1=-0.18875090502685182\n",
      "Gradient Descent(264/499): loss=0.295066833321652, w0=0.22889293983571934, w1=-0.1883681413487291\n",
      "Gradient Descent(265/499): loss=0.2947792573818831, w0=0.22795007921579502, w1=-0.18798181251518833\n",
      "Gradient Descent(266/499): loss=0.2944933692086274, w0=0.2270096136827237, w1=-0.18759197589046997\n",
      "Gradient Descent(267/499): loss=0.2942091543645373, w0=0.22607152790726073, w1=-0.18719868809583065\n",
      "Gradient Descent(268/499): loss=0.2939265985908706, w0=0.2251358067064107, w1=-0.18680200501872052\n",
      "Gradient Descent(269/499): loss=0.29364568780465145, w0=0.2242024350419099, w1=-0.18640198182186207\n",
      "Gradient Descent(270/499): loss=0.2933664080958847, w0=0.22327139801872373, w1=-0.1859986729522309\n",
      "Gradient Descent(271/499): loss=0.2930887457248252, w0=0.2223426808835593, w1=-0.18559213214993908\n",
      "Gradient Descent(272/499): loss=0.29281268711929725, w0=0.22141626902339273, w1=-0.18518241245702163\n",
      "Gradient Descent(273/499): loss=0.29253821887206716, w0=0.22049214796401131, w1=-0.18476956622612697\n",
      "Gradient Descent(274/499): loss=0.29226532773826314, w0=0.21957030336857003, w1=-0.18435364512911176\n",
      "Gradient Descent(275/499): loss=0.291994000632846, w0=0.21865072103616248, w1=-0.18393470016554067\n",
      "Gradient Descent(276/499): loss=0.29172422462812564, w0=0.21773338690040617, w1=-0.18351278167109206\n",
      "Gradient Descent(277/499): loss=0.2914559869513252, w0=0.21681828702804168, w1=-0.18308793932586995\n",
      "Gradient Descent(278/499): loss=0.29118927498218977, w0=0.21590540761754592, w1=-0.18266022216262298\n",
      "Gradient Descent(279/499): loss=0.2909240762506406, w0=0.21499473499775912, w1=-0.18222967857487113\n",
      "Gradient Descent(280/499): loss=0.2906603784344708, w0=0.21408625562652542, w1=-0.18179635632494073\n",
      "Gradient Descent(281/499): loss=0.290398169357086, w0=0.21317995608934714, w1=-0.18136030255190858\n",
      "Gradient Descent(282/499): loss=0.2901374369852836, w0=0.21227582309805226, w1=-0.18092156377945576\n",
      "Gradient Descent(283/499): loss=0.2898781694270758, w0=0.2113738434894753, w1=-0.18048018592363177\n",
      "Gradient Descent(284/499): loss=0.2896203549295498, w0=0.21047400422415133, w1=-0.18003621430052996\n",
      "Gradient Descent(285/499): loss=0.2893639818767676, w0=0.2095762923850229, w1=-0.17958969363387456\n",
      "Gradient Descent(286/499): loss=0.2891090387877047, w0=0.20868069517616, w1=-0.1791406680625203\n",
      "Gradient Descent(287/499): loss=0.28885551431422435, w0=0.2077871999214927, w1=-0.17868918114786528\n",
      "Gradient Descent(288/499): loss=0.28860339723908957, w0=0.2068957940635565, w1=-0.17823527588117763\n",
      "Gradient Descent(289/499): loss=0.2883526764740103, w0=0.20600646516225019, w1=-0.17777899469083697\n",
      "Gradient Descent(290/499): loss=0.28810334105772417, w0=0.20511920089360622, w1=-0.17732037944949106\n",
      "Gradient Descent(291/499): loss=0.28785538015411405, w0=0.20423398904857326, w1=-0.17685947148112854\n",
      "Gradient Descent(292/499): loss=0.2876087830503561, w0=0.20335081753181114, w1=-0.1763963115680686\n",
      "Gradient Descent(293/499): loss=0.28736353915510204, w0=0.20246967436049773, w1=-0.1759309399578679\n",
      "Gradient Descent(294/499): loss=0.28711963799669327, w0=0.2015905476631479, w1=-0.17546339637014596\n",
      "Gradient Descent(295/499): loss=0.2868770692214058, w0=0.20071342567844438, w1=-0.1749937200033293\n",
      "Gradient Descent(296/499): loss=0.286635822591726, w0=0.19983829675408032, w1=-0.17452194954131545\n",
      "Gradient Descent(297/499): loss=0.2863958879846564, w0=0.19896514934561368, w1=-0.17404812316005716\n",
      "Gradient Descent(298/499): loss=0.28615725539005105, w0=0.19809397201533302, w1=-0.17357227853406798\n",
      "Gradient Descent(299/499): loss=0.2859199149089792, w0=0.19722475343113488, w1=-0.1730944528428495\n",
      "Gradient Descent(300/499): loss=0.28568385675211744, w0=0.19635748236541253, w1=-0.17261468277724115\n",
      "Gradient Descent(301/499): loss=0.2854490712381696, w0=0.19549214769395587, w1=-0.17213300454569372\n",
      "Gradient Descent(302/499): loss=0.285215548792313, w0=0.19462873839486278, w1=-0.1716494538804662\n",
      "Gradient Descent(303/499): loss=0.28498327994467165, w0=0.19376724354746117, w1=-0.17116406604374826\n",
      "Gradient Descent(304/499): loss=0.2847522553288166, w0=0.19290765233124238, w1=-0.17067687583370736\n",
      "Gradient Descent(305/499): loss=0.28452246568028855, w0=0.1920499540248052, w1=-0.1701879175904628\n",
      "Gradient Descent(306/499): loss=0.2842939018351487, w0=0.1911941380048109, w1=-0.1696972252019863\n",
      "Gradient Descent(307/499): loss=0.28406655472855225, w0=0.1903401937449486, w1=-0.1692048321099303\n",
      "Gradient Descent(308/499): loss=0.2838404153933462, w0=0.1894881108149118, w1=-0.16871077131538478\n",
      "Gradient Descent(309/499): loss=0.28361547495869077, w0=0.18863787887938482, w1=-0.16821507538456312\n",
      "Gradient Descent(310/499): loss=0.28339172464870294, w0=0.18778948769704013, w1=-0.1677177764544177\n",
      "Gradient Descent(311/499): loss=0.2831691557811245, w0=0.1869429271195456, w1=-0.1672189062381862\n",
      "Gradient Descent(312/499): loss=0.28294775976601005, w0=0.18609818709058243, w1=-0.16671849603086886\n",
      "Gradient Descent(313/499): loss=0.2827275281044374, w0=0.18525525764487277, w1=-0.16621657671463816\n",
      "Gradient Descent(314/499): loss=0.28250845238724065, w0=0.18441412890721773, w1=-0.1657131787641806\n",
      "Gradient Descent(315/499): loss=0.2822905242937607, w0=0.18357479109154515, w1=-0.16520833225197237\n",
      "Gradient Descent(316/499): loss=0.2820737355906209, w0=0.18273723449996737, w1=-0.1647020668534887\n",
      "Gradient Descent(317/499): loss=0.2818580781305178, w0=0.1819014495218487, w1=-0.1641944118523482\n",
      "Gradient Descent(318/499): loss=0.28164354385103557, w0=0.18106742663288267, w1=-0.1636853961453925\n",
      "Gradient Descent(319/499): loss=0.2814301247734774, w0=0.18023515639417875, w1=-0.16317504824770224\n",
      "Gradient Descent(320/499): loss=0.2812178130017165, w0=0.1794046294513588, w1=-0.16266339629754967\n",
      "Gradient Descent(321/499): loss=0.28100660072106576, w0=0.17857583653366274, w1=-0.162150468061289\n",
      "Gradient Descent(322/499): loss=0.28079648019716547, w0=0.17774876845306378, w1=-0.16163629093818466\n",
      "Gradient Descent(323/499): loss=0.28058744377488926, w0=0.17692341610339274, w1=-0.16112089196517881\n",
      "Gradient Descent(324/499): loss=0.2803794838772666, w0=0.17609977045947162, w1=-0.16060429782159807\n",
      "Gradient Descent(325/499): loss=0.28017259300442393, w0=0.1752778225762563, w1=-0.16008653483380067\n",
      "Gradient Descent(326/499): loss=0.2799667637325417, w0=0.17445756358798825, w1=-0.15956762897976437\n",
      "Gradient Descent(327/499): loss=0.27976198871282787, w0=0.17363898470735517, w1=-0.15904760589361602\n",
      "Gradient Descent(328/499): loss=0.27955826067050876, w0=0.17282207722466042, w1=-0.15852649087010323\n",
      "Gradient Descent(329/499): loss=0.2793555724038347, w0=0.17200683250700124, w1=-0.158004308869009\n",
      "Gradient Descent(330/499): loss=0.279153916783102, w0=0.17119324199745575, w1=-0.15748108451950976\n",
      "Gradient Descent(331/499): loss=0.27895328674969017, w0=0.17038129721427847, w1=-0.15695684212447752\n",
      "Gradient Descent(332/499): loss=0.2787536753151145, w0=0.16957098975010437, w1=-0.156431605664727\n",
      "Gradient Descent(333/499): loss=0.27855507556009323, w0=0.16876231127116134, w1=-0.15590539880320792\n",
      "Gradient Descent(334/499): loss=0.27835748063362875, w0=0.16795525351649113, w1=-0.1553782448891435\n",
      "Gradient Descent(335/499): loss=0.2781608837521047, w0=0.1671498082971785, w1=-0.15485016696211565\n",
      "Gradient Descent(336/499): loss=0.27796527819839584, w0=0.16634596749558855, w1=-0.1543211877560973\n",
      "Gradient Descent(337/499): loss=0.27777065732099154, w0=0.16554372306461232, w1=-0.15379132970343276\n",
      "Gradient Descent(338/499): loss=0.27757701453313416, w0=0.16474306702692018, w1=-0.1532606149387666\n",
      "Gradient Descent(339/499): loss=0.27738434331197, w0=0.16394399147422353, w1=-0.1527290653029216\n",
      "Gradient Descent(340/499): loss=0.27719263719771253, w0=0.1631464885665442, w1=-0.15219670234672636\n",
      "Gradient Descent(341/499): loss=0.27700188979282026, w0=0.1623505505314916, w1=-0.15166354733479345\n",
      "Gradient Descent(342/499): loss=0.2768120947611858, w0=0.1615561696635479, w1=-0.15112962124924817\n",
      "Gradient Descent(343/499): loss=0.2766232458273383, w0=0.16076333832336057, w1=-0.15059494479340912\n",
      "Gradient Descent(344/499): loss=0.27643533677565735, w0=0.15997204893704273, w1=-0.15005953839542055\n",
      "Gradient Descent(345/499): loss=0.27624836144959886, w0=0.15918229399548095, w1=-0.1495234222118376\n",
      "Gradient Descent(346/499): loss=0.2760623137509342, w0=0.15839406605365058, w1=-0.14898661613116454\n",
      "Gradient Descent(347/499): loss=0.2758771876389991, w0=0.15760735772993828, w1=-0.1484491397773471\n",
      "Gradient Descent(348/499): loss=0.27569297712995416, w0=0.15682216170547209, w1=-0.14791101251321878\n",
      "Gradient Descent(349/499): loss=0.2755096762960583, w0=0.15603847072345844, w1=-0.14737225344390245\n",
      "Gradient Descent(350/499): loss=0.2753272792649515, w0=0.15525627758852678, w1=-0.14683288142016693\n",
      "Gradient Descent(351/499): loss=0.27514578021894803, w0=0.15447557516608074, w1=-0.1462929150417402\n",
      "Gradient Descent(352/499): loss=0.27496517339434257, w0=0.15369635638165682, w1=-0.14575237266057844\n",
      "Gradient Descent(353/499): loss=0.27478545308072455, w0=0.1529186142202897, w1=-0.1452112723840929\n",
      "Gradient Descent(354/499): loss=0.27460661362030375, w0=0.15214234172588462, w1=-0.1446696320783335\n",
      "Gradient Descent(355/499): loss=0.2744286494072455, w0=0.15136753200059638, w1=-0.14412746937113158\n",
      "Gradient Descent(356/499): loss=0.274251554887017, w0=0.15059417820421542, w1=-0.14358480165520027\n",
      "Gradient Descent(357/499): loss=0.2740753245557425, w0=0.14982227355356018, w1=-0.1430416460911949\n",
      "Gradient Descent(358/499): loss=0.2738999529595672, w0=0.1490518113218764, w1=-0.1424980196107324\n",
      "Gradient Descent(359/499): loss=0.2737254346940328, w0=0.14828278483824273, w1=-0.14195393891937147\n",
      "Gradient Descent(360/499): loss=0.2735517644034603, w0=0.14751518748698303, w1=-0.14140942049955285\n",
      "Gradient Descent(361/499): loss=0.27337893678034375, w0=0.1467490127070849, w1=-0.14086448061350135\n",
      "Gradient Descent(362/499): loss=0.2732069465647509, w0=0.14598425399162468, w1=-0.14031913530608897\n",
      "Gradient Descent(363/499): loss=0.27303578854373506, w0=0.14522090488719863, w1=-0.13977340040766073\n",
      "Gradient Descent(364/499): loss=0.2728654575507534, w0=0.1444589589933605, w1=-0.1392272915368225\n",
      "Gradient Descent(365/499): loss=0.2726959484650958, w0=0.143698409962065, w1=-0.13868082410319274\n",
      "Gradient Descent(366/499): loss=0.27252725621132035, w0=0.1429392514971177, w1=-0.13813401331011677\n",
      "Gradient Descent(367/499): loss=0.27235937575869856, w0=0.14218147735363054, w1=-0.13758687415734627\n",
      "Gradient Descent(368/499): loss=0.27219230212066814, w0=0.14142508133748383, w1=-0.137039421443682\n",
      "Gradient Descent(369/499): loss=0.2720260303542931, w0=0.14067005730479354, w1=-0.13649166976958285\n",
      "Gradient Descent(370/499): loss=0.27186055555973376, w0=0.13991639916138507, w1=-0.1359436335397388\n",
      "Gradient Descent(371/499): loss=0.27169587287972163, w0=0.13916410086227224, w1=-0.13539532696561124\n",
      "Gradient Descent(372/499): loss=0.2715319774990449, w0=0.13841315641114255, w1=-0.13484676406793802\n",
      "Gradient Descent(373/499): loss=0.2713688646440389, w0=0.13766355985984743, w1=-0.13429795867920694\n",
      "Gradient Descent(374/499): loss=0.27120652958208624, w0=0.13691530530789897, w1=-0.13374892444609437\n",
      "Gradient Descent(375/499): loss=0.27104496762112196, w0=0.13616838690197125, w1=-0.13319967483187375\n",
      "Gradient Descent(376/499): loss=0.27088417410914767, w0=0.13542279883540798, w1=-0.13265022311878968\n",
      "Gradient Descent(377/499): loss=0.2707241444337517, w0=0.13467853534773497, w1=-0.13210058241040273\n",
      "Gradient Descent(378/499): loss=0.270564874021637, w0=0.13393559072417846, w1=-0.1315507656339008\n",
      "Gradient Descent(379/499): loss=0.2704063583381548, w0=0.13319395929518826, w1=-0.13100078554238212\n",
      "Gradient Descent(380/499): loss=0.2702485928868458, w0=0.13245363543596675, w1=-0.13045065471710532\n",
      "Gradient Descent(381/499): loss=0.2700915732089879, w0=0.13171461356600236, w1=-0.1299003855697121\n",
      "Gradient Descent(382/499): loss=0.2699352948831501, w0=0.13097688814860908, w1=-0.12934999034441774\n",
      "Gradient Descent(383/499): loss=0.2697797535247528, w0=0.1302404536904701, w1=-0.12879948112017517\n",
      "Gradient Descent(384/499): loss=0.2696249447856349, w0=0.1295053047411875, w1=-0.12824886981280723\n",
      "Gradient Descent(385/499): loss=0.2694708643536269, w0=0.12877143589283582, w1=-0.1276981681771136\n",
      "Gradient Descent(386/499): loss=0.2693175079521293, w0=0.12803884177952188, w1=-0.12714738780894663\n",
      "Gradient Descent(387/499): loss=0.2691648713396986, w0=0.12730751707694798, w1=-0.12659654014726254\n",
      "Gradient Descent(388/499): loss=0.2690129503096376, w0=0.1265774565019815, w1=-0.1260456364761421\n",
      "Gradient Descent(389/499): loss=0.2688617406895927, w0=0.1258486548122278, w1=-0.12549468792678767\n",
      "Gradient Descent(390/499): loss=0.26871123834115607, w0=0.12512110680560912, w1=-0.12494370547949031\n",
      "Gradient Descent(391/499): loss=0.26856143915947434, w0=0.1243948073199471, w1=-0.12439269996557405\n",
      "Gradient Descent(392/499): loss=0.268412339072862, w0=0.12366975123255096, w1=-0.12384168206931064\n",
      "Gradient Descent(393/499): loss=0.26826393404242066, w0=0.12294593345980905, w1=-0.12329066232981262\n",
      "Gradient Descent(394/499): loss=0.26811622006166413, w0=0.1222233489567863, w1=-0.12273965114289707\n",
      "Gradient Descent(395/499): loss=0.26796919315614803, w0=0.12150199271682477, w1=-0.12218865876292884\n",
      "Gradient Descent(396/499): loss=0.2678228493831046, w0=0.12078185977114995, w1=-0.12163769530463457\n",
      "Gradient Descent(397/499): loss=0.26767718483108366, w0=0.12006294518848015, w1=-0.12108677074489749\n",
      "Gradient Descent(398/499): loss=0.2675321956195976, w0=0.11934524407464156, w1=-0.12053589492452305\n",
      "Gradient Descent(399/499): loss=0.2673878778987718, w0=0.11862875157218614, w1=-0.11998507754998647\n",
      "Gradient Descent(400/499): loss=0.2672442278489998, w0=0.1179134628600154, w1=-0.11943432819515132\n",
      "Gradient Descent(401/499): loss=0.2671012416806037, w0=0.11719937315300659, w1=-0.11888365630297117\n",
      "Gradient Descent(402/499): loss=0.2669589156334986, w0=0.11648647770164487, w1=-0.11833307118716216\n",
      "Gradient Descent(403/499): loss=0.2668172459768622, w0=0.11577477179165771, w1=-0.11778258203386023\n",
      "Gradient Descent(404/499): loss=0.2666762290088091, w0=0.1150642507436554, w1=-0.1172321979032487\n",
      "Gradient Descent(405/499): loss=0.2665358610560696, w0=0.11435490991277321, w1=-0.11668192773117236\n",
      "Gradient Descent(406/499): loss=0.2663961384736724, w0=0.11364674468832023, w1=-0.11613178033072129\n",
      "Gradient Descent(407/499): loss=0.26625705764463253, w0=0.11293975049342919, w1=-0.11558176439380292\n",
      "Gradient Descent(408/499): loss=0.2661186149796432, w0=0.11223392278471328, w1=-0.11503188849268321\n",
      "Gradient Descent(409/499): loss=0.2659808069167715, w0=0.11152925705192354, w1=-0.11448216108151797\n",
      "Gradient Descent(410/499): loss=0.2658436299211595, w0=0.11082574881761349, w1=-0.11393259049785236\n",
      "Gradient Descent(411/499): loss=0.26570708048472874, w0=0.11012339363680389, w1=-0.11338318496411269\n",
      "Gradient Descent(412/499): loss=0.26557115512588786, w0=0.10942218709665506, w1=-0.11283395258906531\n",
      "Gradient Descent(413/499): loss=0.265435850389246, w0=0.10872212481613885, w1=-0.11228490136926998\n",
      "Gradient Descent(414/499): loss=0.26530116284532945, w0=0.10802320244571846, w1=-0.11173603919049918\n",
      "Gradient Descent(415/499): loss=0.2651670890903019, w0=0.10732541566702736, w1=-0.11118737382915418\n",
      "Gradient Descent(416/499): loss=0.2650336257456884, w0=0.10662876019255663, w1=-0.11063891295364572\n",
      "Gradient Descent(417/499): loss=0.2649007694581041, w0=0.10593323176534059, w1=-0.110090664125774\n",
      "Gradient Descent(418/499): loss=0.26476851689898545, w0=0.10523882615865147, w1=-0.10954263480207144\n",
      "Gradient Descent(419/499): loss=0.2646368647643261, w0=0.10454553917569165, w1=-0.10899483233514785\n",
      "Gradient Descent(420/499): loss=0.2645058097744157, w0=0.10385336664929545, w1=-0.10844726397499622\n",
      "Gradient Descent(421/499): loss=0.26437534867358264, w0=0.10316230444162783, w1=-0.10789993687030401\n",
      "Gradient Descent(422/499): loss=0.26424547822994027, w0=0.10247234844389327, w1=-0.10735285806972275\n",
      "Gradient Descent(423/499): loss=0.2641161952351364, w0=0.1017834945760406, w1=-0.10680603452314681\n",
      "Gradient Descent(424/499): loss=0.26398749650410636, w0=0.10109573878647897, w1=-0.10625947308294742\n",
      "Gradient Descent(425/499): loss=0.263859378874829, w0=0.10040907705178852, w1=-0.10571318050522\n",
      "Gradient Descent(426/499): loss=0.2637318392080868, w0=0.09972350537644344, w1=-0.10516716345098334\n",
      "Gradient Descent(427/499): loss=0.26360487438722846, w0=0.09903901979252829, w1=-0.10462142848739671\n",
      "Gradient Descent(428/499): loss=0.26347848131793544, w0=0.09835561635946796, w1=-0.10407598208892473\n",
      "Gradient Descent(429/499): loss=0.2633526569279901, w0=0.0976732911637495, w1=-0.10353083063852546\n",
      "Gradient Descent(430/499): loss=0.2632273981670492, w0=0.09699204031865895, w1=-0.10298598042878149\n",
      "Gradient Descent(431/499): loss=0.2631027020064187, w0=0.09631185996400837, w1=-0.10244143766306028\n",
      "Gradient Descent(432/499): loss=0.26297856543883247, w0=0.09563274626587961, w1=-0.10189720845661188\n",
      "Gradient Descent(433/499): loss=0.2628549854782329, w0=0.09495469541635619, w1=-0.10135329883770275\n",
      "Gradient Descent(434/499): loss=0.2627319591595565, w0=0.09427770363327402, w1=-0.1008097147486805\n",
      "Gradient Descent(435/499): loss=0.26260948353851965, w0=0.09360176715995797, w1=-0.1002664620470826\n",
      "Gradient Descent(436/499): loss=0.2624875556914098, w0=0.09292688226497944, w1=-0.09972354650666822\n",
      "Gradient Descent(437/499): loss=0.2623661727148775, w0=0.09225304524189734, w1=-0.09918097381850327\n",
      "Gradient Descent(438/499): loss=0.26224533172573217, w0=0.09158025240902261, w1=-0.09863874959195953\n",
      "Gradient Descent(439/499): loss=0.26212502986074027, w0=0.09090850010916322, w1=-0.09809687935577753\n",
      "Gradient Descent(440/499): loss=0.26200526427642645, w0=0.09023778470939585, w1=-0.0975553685590328\n",
      "Gradient Descent(441/499): loss=0.26188603214887696, w0=0.08956810260081442, w1=-0.09701422257217825\n",
      "Gradient Descent(442/499): loss=0.26176733067354563, w0=0.08889945019830911, w1=-0.09647344668797748\n",
      "Gradient Descent(443/499): loss=0.26164915706506314, w0=0.08823182394031807, w1=-0.09593304612252826\n",
      "Gradient Descent(444/499): loss=0.26153150855704754, w0=0.08756522028861392, w1=-0.09539302601616245\n",
      "Gradient Descent(445/499): loss=0.2614143824019183, w0=0.08689963572805816, w1=-0.09485339143445265\n",
      "Gradient Descent(446/499): loss=0.2612977758707122, w0=0.08623506676639539, w1=-0.09431414736907813\n",
      "Gradient Descent(447/499): loss=0.2611816862529026, w0=0.08557150993401001, w1=-0.09377529873881661\n",
      "Gradient Descent(448/499): loss=0.26106611085621917, w0=0.08490896178372846, w1=-0.0932368503903754\n",
      "Gradient Descent(449/499): loss=0.2609510470064721, w0=0.08424741889057748, w1=-0.0926988070993707\n",
      "Gradient Descent(450/499): loss=0.26083649204737724, w0=0.08358687785159488, w1=-0.09216117357112277\n",
      "Gradient Descent(451/499): loss=0.26072244334038386, w0=0.08292733528558874, w1=-0.09162395444162538\n",
      "Gradient Descent(452/499): loss=0.2606088982645048, w0=0.0822687878329571, w1=-0.09108715427830343\n",
      "Gradient Descent(453/499): loss=0.26049585421614885, w0=0.08161123215544736, w1=-0.09055077758097561\n",
      "Gradient Descent(454/499): loss=0.2603833086089548, w0=0.08095466493598558, w1=-0.09001482878257258\n",
      "Gradient Descent(455/499): loss=0.2602712588736281, w0=0.0802990828784351, w1=-0.08947931225009617\n",
      "Gradient Descent(456/499): loss=0.26015970245777975, w0=0.07964448270743624, w1=-0.08894423228529563\n",
      "Gradient Descent(457/499): loss=0.26004863682576673, w0=0.07899086116816306, w1=-0.08840959312562739\n",
      "Gradient Descent(458/499): loss=0.25993805945853465, w0=0.07833821502617443, w1=-0.0878753989448864\n",
      "Gradient Descent(459/499): loss=0.2598279678534628, w0=0.07768654106716769, w1=-0.08734165385417074\n",
      "Gradient Descent(460/499): loss=0.25971835952421085, w0=0.07703583609684218, w1=-0.08680836190246466\n",
      "Gradient Descent(461/499): loss=0.2596092320005673, w0=0.07638609694064852, w1=-0.08627552707761302\n",
      "Gradient Descent(462/499): loss=0.2595005828283004, w0=0.07573732044366571, w1=-0.08574315330685162\n",
      "Gradient Descent(463/499): loss=0.2593924095690104, w0=0.07508950347034445, w1=-0.08521124445779751\n",
      "Gradient Descent(464/499): loss=0.259284709799984, w0=0.07444264290439957, w1=-0.0846798043389212\n",
      "Gradient Descent(465/499): loss=0.2591774811140507, w0=0.07379673564854528, w1=-0.08414883670055978\n",
      "Gradient Descent(466/499): loss=0.2590707211194408, w0=0.07315177862440486, w1=-0.08361834523532463\n",
      "Gradient Descent(467/499): loss=0.2589644274396449, w0=0.07250776877223558, w1=-0.0830883335791455\n",
      "Gradient Descent(468/499): loss=0.25885859771327574, w0=0.07186470305085803, w1=-0.08255880531160574\n",
      "Gradient Descent(469/499): loss=0.25875322959393193, w0=0.07122257843736789, w1=-0.08202976395702707\n",
      "Gradient Descent(470/499): loss=0.25864832075006206, w0=0.07058139192708766, w1=-0.08150121298472303\n",
      "Gradient Descent(471/499): loss=0.25854386886483205, w0=0.06994114053326218, w1=-0.08097315581013548\n",
      "Gradient Descent(472/499): loss=0.25843987163599336, w0=0.06930182128703602, w1=-0.0804455957949951\n",
      "Gradient Descent(473/499): loss=0.2583363267757528, w0=0.06866343123712891, w1=-0.07991853624852306\n",
      "Gradient Descent(474/499): loss=0.25823323201064435, w0=0.0680259674498428, w1=-0.07939198042748487\n",
      "Gradient Descent(475/499): loss=0.2581305850814026, w0=0.06738942700871269, w1=-0.078865931537473\n",
      "Gradient Descent(476/499): loss=0.2580283837428368, w0=0.06675380701454808, w1=-0.07834039273283788\n",
      "Gradient Descent(477/499): loss=0.25792662576370784, w0=0.06611910458505392, w1=-0.07781536711807023\n",
      "Gradient Descent(478/499): loss=0.2578253089266055, w0=0.06548531685491203, w1=-0.07729085774758956\n",
      "Gradient Descent(479/499): loss=0.25772443102782844, w0=0.06485244097536577, w1=-0.07676686762724858\n",
      "Gradient Descent(480/499): loss=0.2576239898772645, w0=0.06422047411434839, w1=-0.07624339971395573\n",
      "Gradient Descent(481/499): loss=0.25752398329827286, w0=0.06358941345602367, w1=-0.07572045691732822\n",
      "Gradient Descent(482/499): loss=0.2574244091275681, w0=0.06295925620096941, w1=-0.07519804209912048\n",
      "Gradient Descent(483/499): loss=0.25732526521510485, w0=0.062329999565664984, w1=-0.07467615807505741\n",
      "Gradient Descent(484/499): loss=0.2572265494239653, w0=0.06170164078273964, w1=-0.07415480761403503\n",
      "Gradient Descent(485/499): loss=0.25712825963024527, w0=0.0610741771003962, w1=-0.0736339934401718\n",
      "Gradient Descent(486/499): loss=0.257030393722945, w0=0.06044760578273594, w1=-0.07311371823174079\n",
      "Gradient Descent(487/499): loss=0.2569329496038592, w0=0.05982192410910532, w1=-0.07259398462348438\n",
      "Gradient Descent(488/499): loss=0.25683592518746834, w0=0.059197129374511576, w1=-0.0720747952052293\n",
      "Gradient Descent(489/499): loss=0.2567393184008327, w0=0.0585732188888769, w1=-0.0715561525245188\n",
      "Gradient Descent(490/499): loss=0.2566431271834861, w0=0.057950189977561704, w1=-0.07103805908485199\n",
      "Gradient Descent(491/499): loss=0.25654734948733193, w0=0.057328039980507506, w1=-0.07052051734869845\n",
      "Gradient Descent(492/499): loss=0.25645198327653973, w0=0.056706766252888216, w1=-0.07000352973529145\n",
      "Gradient Descent(493/499): loss=0.2563570265274439, w0=0.05608636616411929, w1=-0.06948709862410309\n",
      "Gradient Descent(494/499): loss=0.2562624772284424, w0=0.05546683709866151, w1=-0.06897122635210642\n",
      "Gradient Descent(495/499): loss=0.25616833337989753, w0=0.0548481764548694, w1=-0.06845591521780493\n",
      "Gradient Descent(496/499): loss=0.2560745929940379, w0=0.05423038164597698, w1=-0.06794116747786164\n",
      "Gradient Descent(497/499): loss=0.25598125409486044, w0=0.05361345009875304, w1=-0.06742698535179534\n",
      "Gradient Descent(498/499): loss=0.25588831471803564, w0=0.05299737925470423, w1=-0.06691337101785394\n",
      "Gradient Descent(499/499): loss=0.25579577291081107, w0=0.05238216656849813, w1=-0.06640032661851313\n"
     ]
    }
   ],
   "source": [
    "w_logreg, loss_logreg = f.logistic_regression(y_train_train_lg, tX_train,np.ones(22),500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9054255151525762\n",
      "F1 score:  0.008443465491923641\n"
     ]
    }
   ],
   "source": [
    "y_pred = tX_train_test.dot(w_logreg)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = np.where(y_pred == 1, 1, -1)\n",
    "\n",
    "_,_,_,_,f1 = f.confusion_matrix(y_train_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", np.sum(y_pred == y_train_test)/len(y_train_test))\n",
    "\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [ 0.05238217 -0.06640033  0.02116758 -0.00274931  0.49022348  0.18084201\n",
      " -0.32492353 -0.32597621 -0.52899741 -0.28392638 -0.42508117 -0.12185999\n",
      " -0.17506193 -0.1238589  -0.38367223  0.526824    0.11760777  0.71570066\n",
      "  0.07131136  0.13223593  0.25722637  0.26169432] \n",
      " Loss =  0.25579577291081107 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.00571407674233628\n"
     ]
    }
   ],
   "source": [
    "y_test_logreg = tX_test.dot(w_logreg)\n",
    "y_test_logreg = np.where(y_test_logreg > 0.5, 1, 0)\n",
    "\n",
    "print('weights = \\n', w_logreg,'\\n Loss = ', loss_logreg,'\\n*****************************************************************************',\n",
    "        ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train== 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_logreg == 1)/len(y_test_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/99): loss=22.194147963526632, w0=0.9078302070838765, w1=0.7734125746988572\n",
      "Gradient Descent(1/99): loss=9.553879248884057, w0=0.815752585328088, w1=0.5470517393869585\n",
      "Gradient Descent(2/99): loss=1.275628811054163, w0=0.7239263887868533, w1=0.3212723314856586\n",
      "Gradient Descent(3/99): loss=1.0866978531591471, w0=0.7086874934055847, w1=0.2906129836396613\n",
      "Gradient Descent(4/99): loss=1.0164421060079472, w0=0.70138209336078, w1=0.28243419986045\n",
      "Gradient Descent(5/99): loss=0.9599804311227546, w0=0.6950858445218292, w1=0.2762006208844834\n",
      "Gradient Descent(6/99): loss=0.9139561901309793, w0=0.6892038677378615, w1=0.27026134063383106\n",
      "Gradient Descent(7/99): loss=0.8756876908497888, w0=0.6835594191296854, w1=0.26418521230851383\n",
      "Gradient Descent(8/99): loss=0.8427952517628434, w0=0.6781341712395589, w1=0.25805240609881636\n",
      "Gradient Descent(9/99): loss=0.8136485893783099, w0=0.6729235495850487, w1=0.25198839440245785\n",
      "Gradient Descent(10/99): loss=0.7872596314963121, w0=0.6679004489666673, w1=0.24602570022783482\n",
      "Gradient Descent(11/99): loss=0.7630521631260537, w0=0.6630278695695623, w1=0.24013927232355703\n",
      "Gradient Descent(12/99): loss=0.7406906590852991, w0=0.65827018378082, w1=0.2342862987032837\n",
      "Gradient Descent(13/99): loss=0.7199736422405703, w0=0.6535972346543272, w1=0.22842424100008393\n",
      "Gradient Descent(14/99): loss=0.7007705100177021, w0=0.6489852834921294, w1=0.22251796446624386\n",
      "Gradient Descent(15/99): loss=0.682984883119144, w0=0.6444168382701644, w1=0.2165423119380165\n",
      "Gradient Descent(16/99): loss=0.6665339877727033, w0=0.6398800532775173, w1=0.2104825381767696\n",
      "Gradient Descent(17/99): loss=0.6513379189249903, w0=0.6353679406023933, w1=0.20433359741054846\n",
      "Gradient Descent(18/99): loss=0.6373150430886527, w0=0.6308774908160648, w1=0.19809876130928145\n",
      "Gradient Descent(19/99): loss=0.6243810890759683, w0=0.6264087630647388, w1=0.19178786560168012\n",
      "Gradient Descent(20/99): loss=0.6124502291961634, w0=0.6219640005456845, w1=0.18541542404926467\n",
      "Gradient Descent(21/99): loss=0.6014369831010037, w0=0.6175468249440217, w1=0.17899881184111607\n",
      "Gradient Descent(22/99): loss=0.5912581999398969, w0=0.6131615525001921, w1=0.17255667164151317\n",
      "Gradient Descent(23/99): loss=0.5818347129945973, w0=0.6088126560094888, w1=0.16610763379895813\n",
      "Gradient Descent(24/99): loss=0.5730925077835037, w0=0.6045043768518495, w1=0.15966938066083958\n",
      "Gradient Descent(25/99): loss=0.564963400344037, w0=0.6002404744449946, w1=0.15325803603942045\n",
      "Gradient Descent(26/99): loss=0.5573853021708367, w0=0.5960240900617446, w1=0.14688783039884082\n",
      "Gradient Descent(27/99): loss=0.5503021751681562, w0=0.5918576978744249, w1=0.14057097945871888\n",
      "Gradient Descent(28/99): loss=0.5436637763715318, w0=0.5877431169056977, w1=0.13431771413833124\n",
      "Gradient Descent(29/99): loss=0.5374252749429663, w0=0.5836815613090558, w1=0.12813640776022386\n",
      "Gradient Descent(30/99): loss=0.5315468033914791, w0=0.5796737113445247, w1=0.12203375771542892\n",
      "Gradient Descent(31/99): loss=0.5259929862867602, w0=0.5757197923576791, w1=0.11601499033284875\n",
      "Gradient Descent(32/99): loss=0.5207324747920306, w0=0.5718196533495268, w1=0.11008406782334494\n",
      "Gradient Descent(33/99): loss=0.5157375042852071, w0=0.5679728400853506, w1=0.10424388422056054\n",
      "Gradient Descent(34/99): loss=0.5109834845858735, w0=0.564178660131862, w1=0.09849644317283533\n",
      "Gradient Descent(35/99): loss=0.506448627101607, w0=0.5604362388631988, w1=0.09284301452753174\n",
      "Gradient Descent(36/99): loss=0.5021136098548425, w0=0.5567445665110554, w1=0.08728426927812066\n",
      "Gradient Descent(37/99): loss=0.4979612792932531, w0=0.5531025369219948, w1=0.08182039400107965\n",
      "Gradient Descent(38/99): loss=0.49397638660691645, w0=0.5495089789686349, w1=0.07645118672368845\n",
      "Gradient Descent(39/99): loss=0.4901453556769832, w0=0.5459626816508566, w1=0.07117613649225749\n",
      "Gradient Descent(40/99): loss=0.48645607955601244, w0=0.542462413897542, w1=0.06599448894085615\n",
      "Gradient Descent(41/99): loss=0.48289774238807587, w0=0.5390069399923476, w1=0.060905300022969025\n",
      "Gradient Descent(42/99): loss=0.4794606638219823, w0=0.535595031433224, w1=0.05590747984804375\n",
      "Gradient Descent(43/99): loss=0.47613616319068375, w0=0.5322254759157485, w1=0.05099982831487743\n",
      "Gradient Descent(44/99): loss=0.472916440983363, w0=0.5288970840165491, w1=0.046181063985439134\n",
      "Gradient Descent(45/99): loss=0.4697944753982461, w0=0.5256086940509564, w1=0.04144984741274871\n",
      "Gradient Descent(46/99): loss=0.466763932018341, w0=0.522359175490661, w1=0.03680479993239445\n",
      "Gradient Descent(47/99): loss=0.4638190848902644, w0=0.5191474312526185, w1=0.03224451875127755\n",
      "Gradient Descent(48/99): loss=0.46095474750373316, w0=0.5159723991086984, w1=0.027767589018269062\n",
      "Gradient Descent(49/99): loss=0.4581662123645181, w0=0.5128330524150679, w1=0.02337259343717488\n",
      "Gradient Descent(50/99): loss=0.45544919802680656, w0=0.5097284003193888, w1=0.01905811987963782\n",
      "Gradient Descent(51/99): loss=0.4527998026031313, w0=0.5066574875709856, w1=0.014822767371194355\n",
      "Gradient Descent(52/99): loss=0.45021446290289685, w0=0.5036193940327931, w1=0.010665150754677125\n",
      "Gradient Descent(53/99): loss=0.44768991846599443, w0=0.5006132339728735, w1=0.006583904278871279\n",
      "Gradient Descent(54/99): loss=0.4452231798579363, w0=0.4976381551965722, w1=0.0025776843145166144\n",
      "Gradient Descent(55/99): loss=0.44281150067922703, w0=0.4946933380671083, w1=-0.0013548286375189835\n",
      "Gradient Descent(56/99): loss=0.4404523528160645, w0=0.491777994451867, w1=-0.005214928511378793\n",
      "Gradient Descent(57/99): loss=0.4381434045234659, w0=0.4888913666233244, w1=-0.009003882704813532\n",
      "Gradient Descent(58/99): loss=0.43588250098699294, w0=0.4860327261369367, w1=-0.012722931481458213\n",
      "Gradient Descent(59/99): loss=0.4336676470566002, w0=0.48320137270310676, w1=-0.016373287673378194\n",
      "Gradient Descent(60/99): loss=0.43149699188686036, w0=0.48039663306622116, w1=-0.01995613662382504\n",
      "Gradient Descent(61/99): loss=0.4293688152528574, w0=0.4776178599004986, w1=-0.02347263632105126\n",
      "Gradient Descent(62/99): loss=0.4272815153412042, w0=0.47486443072982926, w1=-0.026923917682954025\n",
      "Gradient Descent(63/99): loss=0.4252335978416184, w0=0.47213574687677273, w1=-0.030311084959623896\n",
      "Gradient Descent(64/99): loss=0.42322366618689583, w0=0.4694312324443036, w1=-0.03363521622686455\n",
      "Gradient Descent(65/99): loss=0.4212504128084548, w0=0.4667503333326631, w1=-0.03689736394866467\n",
      "Gradient Descent(66/99): loss=0.41931261129132963, w0=0.4640925162927164, w1=-0.040098555590642404\n",
      "Gradient Descent(67/99): loss=0.4174091093269474, w0=0.4614572680164787, w1=-0.04323979426980295\n",
      "Gradient Descent(68/99): loss=0.41553882237453665, w0=0.4588440942649029, w1=-0.04632205942868239\n",
      "Gradient Descent(69/99): loss=0.41370072795288254, w0=0.4562525190325975, w1=-0.04934630752420102\n",
      "Gradient Descent(70/99): loss=0.411893860493566, w0=0.4536820837488183, w1=-0.05231347272340181\n",
      "Gradient Descent(71/99): loss=0.4101173066950321, w0=0.4511323465138466, w1=-0.05522446759977733\n",
      "Gradient Descent(72/99): loss=0.408370201323981, w0=0.4486028813696967, w1=-0.05808018382514618\n",
      "Gradient Descent(73/99): loss=0.4066517234168004, w0=0.4460932776039839, w1=-0.06088149285307676\n",
      "Gradient Descent(74/99): loss=0.40496109283920984, w0=0.4436031390857092, w1=-0.06362924659071015\n",
      "Gradient Descent(75/99): loss=0.40329756716705006, w0=0.44113208363168, w1=-0.06632427805653666\n",
      "Gradient Descent(76/99): loss=0.40166043885532116, w0=0.43867974240226737, w1=-0.06896740202225896\n",
      "Gradient Descent(77/99): loss=0.40004903266624, w0=0.43624575932520654, w1=-0.07155941563734916\n",
      "Gradient Descent(78/99): loss=0.3984627033303077, w0=0.43382979054616466, w1=-0.07410109903529773\n",
      "Gradient Descent(79/99): loss=0.3969008334172018, w0=0.4314315039048277, w1=-0.07659321592086968\n",
      "Gradient Descent(80/99): loss=0.3953628313958196, w0=0.42905057843529587, w1=-0.07903651413794541\n",
      "Gradient Descent(81/99): loss=0.3938481298649892, w0=0.4266867038896176, w1=-0.08143172621773424\n",
      "Gradient Descent(82/99): loss=0.3923561839383216, w0=0.424339580283338, w1=-0.08377956990732155\n",
      "Gradient Descent(83/99): loss=0.3908864697684022, w0=0.42200891746198416, w1=-0.08608074867864826\n",
      "Gradient Descent(84/99): loss=0.38943848319704183, w0=0.4196944346874585, w1=-0.08833595221813327\n",
      "Gradient Descent(85/99): loss=0.3880117385196771, w0=0.4173958602433593, w1=-0.09054585689723742\n",
      "Gradient Descent(86/99): loss=0.386605767353205, w0=0.41511293105829594, w1=-0.09271112622433711\n",
      "Gradient Descent(87/99): loss=0.38522011759762, w0=0.4128453923463121, w1=-0.09483241127833028\n",
      "Gradient Descent(88/99): loss=0.3838543524827734, w0=0.4105929972635772, w1=-0.09691035112443788\n",
      "Gradient Descent(89/99): loss=0.38250804969243635, w0=0.40835550658054826, w1=-0.0989455732126953\n",
      "Gradient Descent(90/99): loss=0.3811808005586051, w0=0.40613268836884925, w1=-0.10093869375964962\n",
      "Gradient Descent(91/99): loss=0.3798722093196763, w0=0.4039243177021517, w1=-0.10289031811379364\n",
      "Gradient Descent(92/99): loss=0.3785818924367302, w0=0.40173017637038205, w1=-0.10480104110527617\n",
      "Gradient Descent(93/99): loss=0.37730947796271175, w0=0.39955005260661536, w1=-0.10667144738043258\n",
      "Gradient Descent(94/99): loss=0.37605460495979, w0=0.3973837408260507, w1=-0.10850211172167912\n",
      "Gradient Descent(95/99): loss=0.37481692296062286, w0=0.3952310413764953, w1=-0.11029359935331212\n",
      "Gradient Descent(96/99): loss=0.37359609146965395, w0=0.39309176029981563, w1=-0.11204646623374726\n",
      "Gradient Descent(97/99): loss=0.37239177950092506, w0=0.3909657091038436, w1=-0.1137612593347262\n",
      "Gradient Descent(98/99): loss=0.3712036651492199, w0=0.38885270454425036, w1=-0.11543851690800935\n",
      "Gradient Descent(99/99): loss=0.3700314351916368, w0=0.3867525684159301, w1=-0.11707876874006173\n",
      "Gradient Descent(100/99): loss=0.3688747847169664, w0=0.38466512735345637, w1=-0.1186825363952288\n"
     ]
    }
   ],
   "source": [
    "w_reg_logreg, loss_reg_logreg = f.reg_logistic_regression(y_train_processed_logreg, tX_train, 0.01, initial_w, 100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = \n",
      " [ 0.38466513 -0.11868254  0.03348657 -0.02180457  0.70951366  0.47367152\n",
      "  0.32920329  0.29529946 -0.24753073  0.41312117 -0.88487795 -0.42905013\n",
      "  0.33098771  0.4264872   0.25716685  0.62096664  0.05302878  0.75844239\n",
      "  0.40304051  0.55241231  0.64394116  0.65871171] \n",
      " Loss =  0.3688747847169664 \n",
      "*****************************************************************************  \n",
      " Train sample : \n",
      " Heart attack rate =  0.08830207079403295 \n",
      " \n",
      " Test sample : \n",
      " Heart attack rate =  0.027372713226487717\n"
     ]
    }
   ],
   "source": [
    "y_test_reg_logreg = tX_test.dot(w_reg_logreg)\n",
    "y_test_reg_logreg = np.where(y_test_reg_logreg > 0.5, 1, 0)\n",
    "\n",
    "print('weights = \\n', w_reg_logreg,'\\n Loss = ', loss_reg_logreg,'\\n*****************************************************************************',\n",
    "        ' \\n Train sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_train == 1)/len(y_train), '\\n \\n Test sample : \\n', 'Heart attack rate = ', np.count_nonzero(y_test_reg_logreg == 1)/len(y_test_reg_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = np.where(y_test_reg_logreg == 1, 1, -1)\n",
    "h.create_csv_submission(test_ids, y_sub, 'submission_reg_logreg2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
